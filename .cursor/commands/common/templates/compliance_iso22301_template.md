# Template ISO 22301:2019 - Business Continuity Management System (BCMS)

*Template especializado para gera√ß√£o de documenta√ß√£o ISO 22301:2019 (Business Continuity Management System) com foco em BC/DR e Crisis Management*

---

## Introdu√ß√£o ao ISO 22301:2019

**ISO 22301:2019** √© o padr√£o internacional para Business Continuity Management System (BCMS). Define requisitos para planejar, estabelecer, implementar, operar, monitorar, revisar, manter e melhorar continuamente um sistema documentado de gest√£o para preparar, responder e recuperar de eventos disruptivos.

**Objetivo deste Template:**
Guiar a gera√ß√£o de documenta√ß√£o completa de BCMS que atenda aos requisitos da norma ISO 22301:2019 e prepare a organiza√ß√£o para responder a desastres e manter continuidade operacional.

**Aplic√°vel para:**
- Organiza√ß√µes com processos cr√≠ticos de neg√≥cio
- Fintechs, SaaS, Healthcare, infraestrutura cr√≠tica
- Empresas que precisam demonstrar resili√™ncia para clientes/parceiros
- Resposta a requisitos de Due Diligence (ex: Serasa Experian)
- Prepara√ß√£o para certifica√ß√£o ISO 22301

---

## üéØ **Mapeamento Due Diligence Serasa Experian**

**CR√çTICO:** Este template mapeia **5 de 8 requisitos** da solicita√ß√£o Serasa Experian:

| # | Requisito Serasa | Documento ISO 22301 | Status |
|---|------------------|---------------------|--------|
| 1 | Plano de Continuidade de Neg√≥cios | `business-continuity-plan.md` | ‚úÖ |
| 2 | Plano de Recupera√ß√£o de Desastres | `disaster-recovery-plan.md` | ‚úÖ |
| 3 | Plano de Gerenciamento de Crise | `crisis-management.md` | ‚úÖ |
| 4 | Evid√™ncias de testes anuais BC/DR | `resilience-testing.md` | ‚úÖ |
| 5 | Pol√≠tica backup/restaura√ß√£o RTOs/RPOs | `recovery-objectives.md` | ‚úÖ |
| 6 | Certificado ISO 22301 ou SOC2 | (Certifica√ß√£o opcional) | üîÑ |
| 7 | Confirma√ß√£o SLAs | ‚Üí SOC2 Template | - |
| 8 | Documenta√ß√£o Contratual SLAs | ‚Üí SOC2 Template | - |

**Cobertura Serasa:** 5/5 requisitos de BC/DR ‚úÖ

---

## Documentos Obrigat√≥rios do BCMS

O specialist agent `@iso-22301-specialist` deve gerar **5 documentos principais**:

| # | Documento | Arquivo | Se√ß√£o ISO 22301 | Requisito Serasa |
|---|-----------|---------|-----------------|------------------|
| 1 | Business Continuity Plan (BCP) | `business-continuity-plan.md` | Cl√°usula 8.4 | ‚úÖ Req #1 |
| 2 | Disaster Recovery Plan (DRP) | `disaster-recovery-plan.md` | Cl√°usula 8.4.3 | ‚úÖ Req #2 |
| 3 | Plano de Gerenciamento de Crise | `crisis-management.md` | Cl√°usula 8.4.4 | ‚úÖ Req #3 |
| 4 | Testes de Resili√™ncia | `resilience-testing.md` | Cl√°usula 8.5 | ‚úÖ Req #4 |
| 5 | Recovery Objectives (RTOs/RPOs) | `recovery-objectives.md` | Cl√°usula 8.2.3 | ‚úÖ Req #5 |

**Output Directory:** `docs/compliance/business-continuity/`

---

## 1. business-continuity-plan.md

### Objetivo
Documentar o Business Continuity Plan (BCP) da organiza√ß√£o conforme ISO 22301:2019 Cl√°usula 8.4, estabelecendo estrat√©gias e procedimentos para manter opera√ß√µes cr√≠ticas durante e ap√≥s eventos disruptivos.

**Responde:** ‚úÖ **Serasa Req #1** - "Plano de Continuidade de Neg√≥cios: √™nfase nos processos que sustentam nosso contrato"

### Se√ß√µes Obrigat√≥rias

#### 1.1 Escopo do BCP (PT-BR)
```markdown
# Business Continuity Plan (BCP) - [Nome da Empresa]

## Escopo

### Processos Cr√≠ticos Cobertos
Este BCP cobre os seguintes processos cr√≠ticos que sustentam opera√ß√µes com clientes enterprise (incluindo Serasa Experian):

1. **Processamento de Transa√ß√µes Financeiras**
   - Escopo: APIs de pagamento, autoriza√ß√£o, liquida√ß√£o
   - Criticidade: Cr√≠tica
   - Sistemas: Payment Gateway, Risk Engine, Core Banking APIs

2. **Autentica√ß√£o e Autoriza√ß√£o de Usu√°rios**
   - Escopo: Login, SSO, MFA, gest√£o de sess√µes
   - Criticidade: Cr√≠tica
   - Sistemas: Auth Service (Auth0), User Database, Session Store

3. **APIs Core de Integra√ß√£o**
   - Escopo: APIs RESTful que clientes dependem
   - Criticidade: Cr√≠tica
   - Sistemas: API Gateway, Backend Services, Cache Layer

4. **Processamento de Dados e Analytics**
   - Escopo: ETL, dashboards, relat√≥rios para clientes
   - Criticidade: Alta
   - Sistemas: Data Pipeline, Analytics DB, BI Tools

### √Åreas Organizacionais Inclu√≠das
- Engineering (Backend, DevOps, SRE)
- Product (decis√µes de prioriza√ß√£o em crises)
- Customer Success (comunica√ß√£o com clientes)
- Security (valida√ß√£o de seguran√ßa p√≥s-recupera√ß√£o)

### Exclus√µes
- Processos administrativos n√£o-cr√≠ticos (RH, financeiro interno)
- Sistemas de desenvolvimento/staging (apenas produ√ß√£o √© coberto)
```

#### 1.2 Business Impact Analysis (BIA)
```markdown
## Business Impact Analysis (BIA)

### Metodologia
An√°lise conduzida em [Data] com stakeholders de Engineering, Product e Customer Success.

### Processos Cr√≠ticos Identificados

#### Processo 1: Processamento de Transa√ß√µes Financeiras

**Maximum Tolerable Period of Disruption (MTPD):** 4 horas  
**Recovery Time Objective (RTO):** 1 hora  
**Recovery Point Objective (RPO):** 15 minutos

**Impactos se Indispon√≠vel:**
- **Financeiro:** R$ 500K/hora em transa√ß√µes n√£o processadas
- **Reputacional:** Perda de confian√ßa de clientes enterprise
- **Legal:** Viola√ß√£o de SLAs contratuais (multas ~R$ 100K/dia)
- **Operacional:** Backlog de transa√ß√µes, necessidade de reconcilia√ß√£o manual

**Depend√™ncias Cr√≠ticas:**
- AWS RDS (PostgreSQL Multi-AZ)
- AWS ElastiCache (Redis)
- Payment Provider APIs (Stripe, PagSeguro)
- Risk Engine (interno)

---

#### Processo 2: Autentica√ß√£o de Usu√°rios

**MTPD:** 2 horas  
**RTO:** 30 minutos  
**RPO:** 0 (sem perda de dados aceit√°vel)

**Impactos se Indispon√≠vel:**
- **Financeiro:** Usu√°rios n√£o conseguem fazer login = zero transa√ß√µes
- **Reputacional:** Percep√ß√£o de instabilidade da plataforma
- **Legal:** Viola√ß√£o de SLAs (disponibilidade 99.9%)
- **Operacional:** Suporte sobrecarregado com tickets

**Depend√™ncias Cr√≠ticas:**
- Auth0 (SaaS, SLA 99.99%)
- AWS RDS (user database)
- Redis (session store)

---

[Adicionar outros processos cr√≠ticos]

### Matriz de Criticidade

| Processo | MTPD | RTO | RPO | Prioridade Recupera√ß√£o |
|----------|------|-----|-----|------------------------|
| Processamento de Transa√ß√µes | 4h | 1h | 15min | P1 (M√°xima) |
| Autentica√ß√£o de Usu√°rios | 2h | 30min | 0 | P1 (M√°xima) |
| APIs Core | 4h | 2h | 1h | P1 (M√°xima) |
| Analytics/Dashboards | 24h | 8h | 4h | P2 (Alta) |
| Backoffice/Admin | 72h | 24h | 24h | P3 (M√©dia) |
```

#### 1.3 Estrat√©gias de Continuidade (PT-BR + EN-US)
```markdown
## Estrat√©gias de Continuidade

### Estrat√©gia 1: Alta Disponibilidade (High Availability)

**Objetivo:** Prevenir disrup√ß√µes atrav√©s de redund√¢ncia.

**Implementa√ß√£o:**
- **Multi-AZ Deployment (AWS):** Todos servi√ßos cr√≠ticos em 3 zonas de disponibilidade
- **Auto-Scaling:** Escalamento autom√°tico baseado em demanda (min: 3 nodes, max: 20)
- **Load Balancing:** Application Load Balancer (ALB) com health checks
- **Database Replication:** PostgreSQL com hot standby (replica√ß√£o s√≠ncrona)
- **Cache Redundancy:** Redis Cluster (3 master nodes + 3 replicas)

**RTO Alcan√ßado:** ~0 (failover autom√°tico em segundos)

---

### Estrat√©gia 2: Disaster Recovery (Multi-Region)

**Objetivo:** Recuperar opera√ß√µes se regi√£o AWS prim√°ria falhar completamente.

**Implementa√ß√£o:**
- **Primary Region:** us-east-1 (N. Virginia)
- **DR Region:** us-west-2 (Oregon)
- **Data Replication:** Cross-region replication ass√≠ncrona (RDS, S3)
- **Failover Strategy:** Warm standby (DR region com capacidade reduzida, 30% da prod)
- **DNS Failover:** Route53 health checks + automatic failover

**RTO Alcan√ßado:** 2 horas (provisionamento de capacidade + smoke tests)  
**RPO Alcan√ßado:** 1 hora (replica√ß√£o ass√≠ncrona)

---

### Estrat√©gia 3: Backup e Restore

**Objetivo:** Recuperar dados em caso de corrup√ß√£o, ransomware ou erro humano.

**Implementa√ß√£o:**
- **Automated Backups:**
  - RDS: Snapshots di√°rios (reten√ß√£o 30 dias) + transaction logs (PITR at√© 5min atr√°s)
  - S3: Versioning habilitado + lifecycle policies
  - C√≥digo: GitHub (versionamento completo)
- **Backup Testing:** Restore semanal em ambiente isolado
- **Backup Encryption:** AES-256 (at rest), TLS 1.3 (in transit)
- **Offsite Storage:** Backups replicados para bucket S3 em regi√£o secund√°ria

**RTO Alcan√ßado:** 4 horas (restore completo de backup mais recente)  
**RPO Alcan√ßado:** 5 minutos (PITR do RDS)
```

#### 1.4 Procedimentos de Ativa√ß√£o do BCP
```markdown
## Ativa√ß√£o do Business Continuity Plan

### Gatilhos de Ativa√ß√£o

O BCP √© ativado quando:
1. **Outage Prolongado:** Servi√ßo cr√≠tico indispon√≠vel por > 30 minutos
2. **Disaster Regional:** AWS Region inteira comprometida
3. **Cyberattack Severo:** Ransomware, data breach massivo
4. **Disaster Natural:** Terremoto, furac√£o, inc√™ndio no data center
5. **Falha Cr√≠tica de Fornecedor:** Payment provider down, Auth0 indispon√≠vel

### Processo de Ativa√ß√£o

#### Step 1: Declara√ß√£o de Incidente (0-15min)
- **Quem:** On-call SRE ou DevOps Lead
- **A√ß√£o:** Declarar "Business Continuity Incident" via PagerDuty
- **Notifica√ß√£o:** CTO, Engineering Manager, CISO alertados automaticamente

#### Step 2: Ativa√ß√£o do Crisis Team (15-30min)
- **Quem:** CTO convoca Crisis Management Team
- **A√ß√£o:** Confer√™ncia de emerg√™ncia (Zoom + Slack #crisis)
- **Decis√£o:** Avaliar situa√ß√£o e aprovar ativa√ß√£o do BCP

#### Step 3: Execu√ß√£o de Estrat√©gia (30min+)
Baseado no tipo de incidente:
- **HA Failover:** Autom√°tico (gerenciado por AWS/Kubernetes)
- **DR Multi-Region:** Manual (seguir DRP - disaster-recovery-plan.md)
- **Backup Restore:** Manual (seguir runbook espec√≠fico)

#### Step 4: Comunica√ß√£o (Paralelo)
- **Interno:** Update em #crisis e all-hands meeting
- **Externo:** Status page atualizada, email para clientes enterprise
- **Regulat√≥rio:** Notifica√ß√£o se houver impacto em dados (LGPD)

### Autoridade de Ativa√ß√£o

| Incidente | Autoridade | Backup |
|-----------|------------|--------|
| Outage < 1h | On-call SRE | DevOps Lead |
| Outage > 1h | CTO | Engineering Manager |
| Regional Disaster | CTO + CEO | Board |
| Data Breach | CISO + CTO + Legal | CEO |
```

### Guidelines de Conte√∫do
- **Idioma:** BCP (termo em ingl√™s), explica√ß√µes em PT-BR
- **Atualiza√ß√£o:** Semestral ou ap√≥s mudan√ßas significativas
- **Respons√°vel:** DevOps Lead + SRE Team
- **Aprova√ß√£o:** CTO

---

## 2. disaster-recovery-plan.md

### Objetivo
Documentar o Disaster Recovery Plan (DRP) conforme ISO 22301:2019 Cl√°usula 8.4.3, especificando procedimentos t√©cnicos detalhados para restaurar infraestrutura e sistemas cr√≠ticos ap√≥s um desastre.

**Responde:** ‚úÖ **Serasa Req #2** - "Plano de Recupera√ß√£o de Desastres: √™nfase no ambiente tecnol√≥gico que sustenta nosso contrato"

### Se√ß√µes Obrigat√≥rias

#### 2.1 Escopo T√©cnico do DRP (PT-BR + EN-US)
```markdown
# Disaster Recovery Plan (DRP) - Infraestrutura T√©cnica

## Escopo

### Ambientes Cobertos
- **Produ√ß√£o (Production):** 100% dos servi√ßos cr√≠ticos
- **Staging:** N√£o coberto (pode ser recriado de IaC)
- **Development:** N√£o coberto

### Infraestrutura AWS (Primary Region: us-east-1)

#### Compute Layer
- **EKS Cluster:** 3 node groups (on-demand + spot)
  - Namespace: production, monitoring, ingress
  - Workloads: 45 microservices containerizados
- **EC2 Instances:** Bastion hosts, CI/CD runners
- **Lambda Functions:** Processamento ass√≠ncrono, webhooks

#### Data Layer
- **RDS PostgreSQL:** Multi-AZ, automated backups
  - Primary: db-production-1 (db.r6g.2xlarge)
  - Replica: db-production-2 (read replica)
  - Backup: Snapshots di√°rios + PITR
- **ElastiCache Redis:** Cluster mode enabled
  - 3 shards √ó 2 replicas = 6 nodes total
- **S3 Buckets:** Static assets, backups, logs
  - Versioning + Cross-region replication

#### Networking
- **VPC:** 10.0.0.0/16
  - Public Subnets (3 AZs): ALB, NAT Gateways
  - Private Subnets (3 AZs): EKS nodes, RDS
- **Route53:** DNS com health checks + failover
- **CloudFront:** CDN para assets est√°ticos

### Recovery Site (DR Region: us-west-2)
- **Estrat√©gia:** Warm Standby (30% capacity)
- **RDS Replica:** Cross-region read replica (async)
- **S3 Replication:** Continuous cross-region replication
- **EKS Cluster:** Pre-provisioned (scaled down)
```

#### 2.2 Recovery Procedures (Procedimentos de Recupera√ß√£o)
```markdown
## Procedimentos de Disaster Recovery

### Cen√°rio 1: Regional Outage (AWS Region Completa Down)

**RTO:** 2 horas  
**RPO:** 1 hora

#### Runbook: Multi-Region Failover

**Pre-Requisites:**
- [ ] DR region (us-west-2) tem infraestrutura base provisionada
- [ ] Cross-region replication ativo e validado
- [ ] Runbook testado nos √∫ltimos 6 meses

**Steps:**

##### 1. Declarar Disaster (0-15min)
```bash
# On-call SRE executa:
./scripts/dr-declare-disaster.sh --region us-east-1 --type regional-outage

# A√ß√µes autom√°ticas:
# - PagerDuty alert P0 (CTO, DevOps Lead)
# - Slack #crisis-management notification
# - Status page: "Major Outage - Activating DR"
```

##### 2. Promote DR Database (15-30min)
```bash
# Promover RDS read replica para primary
aws rds promote-read-replica \
  --db-instance-identifier dr-db-production-us-west-2 \
  --region us-west-2

# Aguardar promo√ß√£o (5-10min)
aws rds wait db-instance-available \
  --db-instance-identifier dr-db-production-us-west-2 \
  --region us-west-2

# Validar:
# - Replication lag: 0 (agora √© primary)
# - Write operations: enabled
```

##### 3. Scale DR Kubernetes Cluster (Paralelo 15-45min)
```bash
# Escalar EKS nodegroups para capacidade prod (100%)
eksctl scale nodegroup \
  --cluster dr-production-us-west-2 \
  --name production-nodes \
  --nodes 10 \
  --region us-west-2

# Deploy de aplica√ß√µes (via ArgoCD)
kubectl apply -f k8s/production/ --context dr-us-west-2

# Aguardar pods ready
kubectl wait --for=condition=ready pod \
  --all --namespace=production \
  --timeout=600s
```

##### 4. Update DNS (45-60min)
```bash
# Route53 failover (manual trigger)
aws route53 change-resource-record-sets \
  --hosted-zone-id Z1234567890ABC \
  --change-batch file://dr-dns-failover.json

# JSON:
{
  "Changes": [{
    "Action": "UPSERT",
    "ResourceRecordSet": {
      "Name": "api.empresa.com",
      "Type": "A",
      "AliasTarget": {
        "HostedZoneId": "Z9876543210XYZ",
        "DNSName": "dr-alb.us-west-2.elb.amazonaws.com",
        "EvaluateTargetHealth": true
      }
    }
  }]
}
```

##### 5. Smoke Tests & Validation (60-90min)
```bash
# Executar suite de testes de produ√ß√£o
./scripts/dr-smoke-tests.sh --region us-west-2

# Testes cr√≠ticos:
# - Health checks: /health, /ready
# - Auth flow: login, token refresh
# - Payment processing: transaction end-to-end
# - Database connectivity: read + write
# - External integrations: Stripe, Auth0, Serasa APIs

# Validar m√©tricas:
# - Latency < 200ms (p95)
# - Error rate < 0.1%
# - Throughput > 80% da capacidade normal
```

##### 6. Full Monitoring Activation (90-120min)
```bash
# Ativar monitoramento completo no DR region
terraform apply -target=module.monitoring_dr \
  -var="region=us-west-2" \
  -var="alerting=enabled"

# Dashboards:
# - Grafana: https://grafana.empresa.com (updated to DR metrics)
# - CloudWatch: us-west-2 custom dashboard
# - PagerDuty: Update on-call rotations para DR region

# Alertas configurados:
# - High latency (> 500ms)
# - Error rate (> 1%)
# - Database connections (> 80% pool)
# - Disk space (> 85%)
```

**Rollback:** Se DR failover falhar, reverter DNS para regi√£o original (se recuperada).

---

### Cen√°rio 2: Database Corruption / Ransomware

**RTO:** 4 horas  
**RPO:** 5 minutos

#### Runbook: Database Point-in-Time Recovery (PITR)

**Steps:**

##### 1. Identify Corruption Timestamp
```bash
# Analisar logs para identificar quando corrup√ß√£o come√ßou
aws rds describe-db-log-files \
  --db-instance-identifier db-production-1

# Identificar timestamp exato (ex: 2025-06-03 14:32:00 UTC)
RESTORE_TIME="2025-06-03T14:30:00Z"
```

##### 2. Restore to New Instance
```bash
# Criar nova inst√¢ncia RDS de backup PITR
aws rds restore-db-instance-to-point-in-time \
  --source-db-instance-identifier db-production-1 \
  --target-db-instance-identifier db-production-restored \
  --restore-time "$RESTORE_TIME" \
  --db-instance-class db.r6g.2xlarge \
  --multi-az

# Aguardar restore (30-60min dependendo do tamanho)
```

##### 3. Validate Restored Data
```bash
# Conectar ao DB restaurado e validar integridade
psql -h db-production-restored.xyz.us-east-1.rds.amazonaws.com \
     -U admin -d production

# Queries de valida√ß√£o:
SELECT COUNT(*) FROM users;  -- Confirmar total de registros
SELECT MAX(created_at) FROM transactions;  -- Confirmar √∫ltimo timestamp
SELECT * FROM critical_table WHERE id = 'test-corruption';  -- Confirmar dados n√£o corrompidos
```

##### 4. Swap Databases
```bash
# Promover restored DB para production (downtime ~5min)
# 1. Colocar app em maintenance mode
kubectl scale deployment/api --replicas=0

# 2. Update DNS/connection string
aws ssm put-parameter \
  --name /production/database/endpoint \
  --value "db-production-restored.xyz.us-east-1.rds.amazonaws.com" \
  --overwrite

# 3. Restart aplica√ß√µes
kubectl scale deployment/api --replicas=10
```

---

### Cen√°rio 3: Complete Data Center Failure (Falha F√≠sica)

**RTO:** 6 horas (pior caso)  
**RPO:** 1 hora

#### Runbook: Full Infrastructure Recreation from IaC

**Steps:**
1. Provisionar nova infraestrutura via Terraform em regi√£o DR
2. Restaurar dados de backups S3 cross-region
3. Rebuild Kubernetes cluster e deploy de aplica√ß√µes
4. Update DNS para nova infraestrutura
5. Smoke tests e go-live

*Runbook detalhado em: `docs/devops/runbooks/dr-full-rebuild.md`*
```

#### 2.3 Backup Strategy (Estrat√©gia de Backup)
```markdown
## Estrat√©gia de Backup e Restaura√ß√£o

### Automated Backup Schedule

| Tipo | Frequ√™ncia | Reten√ß√£o | RPO | Teste de Restore |
|------|------------|----------|-----|------------------|
| **RDS Snapshots** | Di√°rio 02:00 UTC | 30 dias | 24h | Semanal |
| **RDS Transaction Logs** | Cont√≠nuo | 7 dias | 5min | Di√°rio (PITR) |
| **Redis AOF** | Cada escrita | 3 dias | 1s | Semanal |
| **S3 Objects** | Versioning | 90 dias | 0 (versionado) | Mensal |
| **EKS Configs** | Git commit | Infinito | 0 (versionado) | Cada deploy |
| **Secrets (Vault)** | Backup di√°rio | 30 dias | 24h | Mensal |

### Backup Testing Procedures

#### Teste Semanal: RDS PITR
- Restaurar snapshot mais recente em ambiente isolado
- Validar integridade de dados (checksums)
- Executar queries de valida√ß√£o
- Documentar tempo de restore
- Deletar inst√¢ncia de teste

#### Teste Mensal: Full DR Drill
- Simular disaster regional
- Executar procedimento completo de failover
- Validar RTOs/RPOs atingidos
- Documentar li√ß√µes aprendidas
- Atualizar runbooks se necess√°rio

**Respons√°vel:** DevOps Team  
**Aprova√ß√£o:** CTO
```

### Guidelines de Conte√∫do
- **Idioma:** DRP, RTO, RPO (termos t√©cnicos), procedimentos em PT-BR
- **Atualiza√ß√£o:** Ap√≥s cada teste de DR ou mudan√ßa de infraestrutura
- **Respons√°vel:** DevOps Lead + SRE
- **Treinamento:** Simula√ß√µes trimestrais (tabletop + hands-on)

---

## 3. crisis-management.md

### Objetivo
Documentar o Plano de Gerenciamento de Crise conforme ISO 22301:2019 Cl√°usula 8.4.4, estabelecendo estrutura de comando, comunica√ß√£o e coordena√ß√£o durante crises que impactam continuidade de neg√≥cio.

**Responde:** ‚úÖ **Serasa Req #3** - "Plano de Gerenciamento de Crise: indicando canais de atua√ß√£o e pontos de contato da Serasa Experian"

### Se√ß√µes Obrigat√≥rias

#### 3.1 Crisis Management Team (CMT)
```markdown
# Plano de Gerenciamento de Crise

## Crisis Management Team (CMT)

### Estrutura de Comando

#### Crisis Manager (Chair)
**Nome:** [CTO - Nome Completo]  
**Responsabilidades:**
- Declarar estado de crise
- Convocar CMT e coordenar resposta
- Tomar decis√µes estrat√©gicas
- Comunicar com CEO e Board
- Autorizar gastos de emerg√™ncia

**Contato:**
- Celular: +55 11 XXXX-XXXX (24/7)
- Email: cto@empresa.com
- Slack: @cto (notifica√ß√µes push)

**Backup:** Engineering Manager

---

#### Technical Lead
**Nome:** [DevOps Lead - Nome]  
**Responsabilidades:**
- Coordenar a√ß√µes t√©cnicas de recupera√ß√£o
- Liderar execu√ß√£o de runbooks
- Reportar status t√©cnico ao Crisis Manager

**Contato:**
- Celular: +55 11 YYYY-YYYY
- Email: devops-lead@empresa.com
- PagerDuty: Primary on-call

**Backup:** SRE Lead

---

#### Communications Lead
**Nome:** [VP Marketing / Customer Success]  
**Responsabilidades:**
- Gerenciar comunica√ß√£o externa (clientes, parceiros)
- Atualizar status page e redes sociais
- Coordenar comunicados oficiais
- Interface com Serasa e outros clientes enterprise

**Contato:**
- Celular: +55 11 ZZZZ-ZZZZ
- Email: comms@empresa.com

---

#### Security Lead
**Nome:** [CISO - Nome]  
**Responsabilidades:**
- Avaliar impactos de seguran√ßa
- Coordenar resposta a breaches
- Garantir compliance regulat√≥rio
- Notifica√ß√µes LGPD/GDPR se necess√°rio

**Contato:**
- Celular: +55 11 AAAA-AAAA
- Email: ciso@empresa.com
```

#### 3.2 Canais de Comunica√ß√£o (PT-BR + Contacts)
```markdown
## Canais de Comunica√ß√£o Durante Crise

### Comunica√ß√£o Interna

#### War Room Virtual
- **Platform:** Zoom (link permanente: https://zoom.us/j/crisis-empresa)
- **Backup:** Google Meet
- **Participantes:** CMT + especialistas conforme necess√°rio

#### Slack Channels
- **#crisis-management:** Coordena√ß√£o do CMT (privado)
- **#incident-response:** Atualiza√ß√µes t√©cnicas (p√∫blico interno)
- **#company-wide-updates:** Comunicados para toda empresa

---

### Comunica√ß√£o Externa

#### Status Page
- **URL:** https://status.empresa.com
- **Updates:** A cada 30 minutos durante crise
- **Respons√°vel:** Communications Lead

#### Clientes Enterprise (Direct Communication)

**Template de Email:**
```
Assunto: [URGENTE] Atualiza√ß√£o sobre Incidente - [Nome da Empresa]

Prezado Cliente,

Estamos atualmente gerenciando um incidente que pode impactar [servi√ßos afetados].

Status Atual: [descri√ß√£o]
A√ß√µes Tomadas: [resumo]
Pr√≥xima Atualiza√ß√£o: [timeframe]

Para quest√µes urgentes, contate:
- Nome: [Crisis Manager]
- Email: crisis@empresa.com
- Telefone: +55 11 XXXX-XXXX (24/7)

Atenciosamente,
[Nome do Communications Lead]
[Cargo]
```

---

### üîó Pontos de Contato Serasa Experian (Due Diligence)

**CR√çTICO:** Canais espec√≠ficos para comunica√ß√£o com Serasa durante crise:

| Tipo de Comunica√ß√£o | Contato Empresa | Contato Serasa (Exemplo) |
|---------------------|-----------------|--------------------------|
| **Incident Notification** | crisis@empresa.com | [email-serasa-bc@serasaexperian.com] |
| **Emergency Phone** | +55 11 XXXX-XXXX (CTO) | [+55 11 contato-serasa] |
| **Status Updates** | status.empresa.com | Portal do Cliente Serasa |
| **Post-Incident Report** | cto@empresa.com | [account-manager@serasa] |

**Processo de Notifica√ß√£o Serasa:**
1. **Declara√ß√£o de Crise:** Notificar Serasa dentro de 1 hora se servi√ßos impactados
2. **Updates Regulares:** A cada 2 horas at√© resolu√ß√£o
3. **Post-Incident Report:** Enviar relat√≥rio completo dentro de 48h ap√≥s resolu√ß√£o

**Template de Notifica√ß√£o:**
```
Para: [contato-bc@serasaexperian.com]
CC: [account-manager@serasa], cto@empresa.com
Assunto: [CRISE] Notifica√ß√£o de Incidente - [Empresa] - [Data/Hora]

Prezados,

Conforme nosso Plano de Gerenciamento de Crise, notificamos incidente que pode impactar servi√ßos:

- Tipo de Incidente: [ex: Falha Regional AWS]
- Severidade: [P0/P1/P2]
- Servi√ßos Impactados: [APIs de integra√ß√£o, autentica√ß√£o]
- Impacto Estimado: [downtime, degrada√ß√£o]
- A√ß√µes em Andamento: [ativa√ß√£o de DR, failover multi-region]
- ETA de Resolu√ß√£o: [estimativa]
- Pr√≥ximo Update: [hor√°rio]

Crisis Manager:
Nome: [CTO - Nome Completo]
Celular: +55 11 XXXX-XXXX
Email: crisis@empresa.com

Atenciosamente,
[Nome]
[Cargo]
```
```

#### 3.3 Escalation Matrix (Matriz de Escala√ß√£o)
```markdown
## Matriz de Escala√ß√£o de Crise

### N√≠veis de Severidade

| N√≠vel | Crit√©rio | Notifica√ß√£o | Response Time |
|-------|----------|-------------|---------------|
| **P0 - Cr√≠tico** | Servi√ßo core down > 1h, data breach, regional disaster | CEO, Board, Todos clientes enterprise | Imediata |
| **P1 - Alto** | Servi√ßo core degradado, outage parcial < 1h | CTO, CMT, Clientes afetados | 15 minutos |
| **P2 - M√©dio** | Servi√ßo n√£o-cr√≠tico down, degrada√ß√£o controlada | CMT, Status page | 30 minutos |
| **P3 - Baixo** | Issue isolado, sem impacto em clientes | Incident response team | 1 hora |

### Escalation Path

```mermaid
graph TD
    A[Incident Detected] --> B{Severity?}
    B -->|P3| C[On-call Engineer]
    B -->|P2| D[DevOps Lead]
    B -->|P1| E[CTO + CMT]
    B -->|P0| F[CEO + Board]
    
    C --> G{Resolved < 1h?}
    G -->|No| D
    D --> H{Resolved < 2h?}
    H -->|No| E
    E --> I{Crisis Declared?}
    I -->|Yes| F
```

### Decision-Making Authority

| Decis√£o | Autoridade | Backup |
|---------|------------|--------|
| Declarar Estado de Crise | CTO | CEO |
| Ativar DR Multi-Region | CTO | DevOps Lead |
| Comunicar Breach para Reguladores | CISO + Legal | CEO |
| Gastos de Emerg√™ncia (< R$ 50K) | CTO | CFO |
| Gastos de Emerg√™ncia (> R$ 50K) | CEO | Board |
```

### Guidelines de Conte√∫do
- **Idioma:** Crisis Management (termo t√©cnico), procedimentos em PT-BR
- **CR√çTICO:** Incluir contatos espec√≠ficos de clientes enterprise (Serasa)
- **Atualiza√ß√£o:** Trimestral ou quando houver mudan√ßa de stakeholders
- **Respons√°vel:** CTO + Communications Lead

---

## 4. resilience-testing.md

### Objetivo
Documentar testes de resili√™ncia conforme ISO 22301:2019 Cl√°usula 8.5, evidenciando execu√ß√£o de exerc√≠cios, resultados e melhorias implementadas.

**Responde:** ‚úÖ **Serasa Req #4** - "Evid√™ncias da divulga√ß√£o de Workshops e/ou treinamentos internos sobre Resili√™ncia + Evid√™ncia de testes anuais dos Planos de Continuidade e Recupera√ß√£o de Desastres"

### Se√ß√µes Obrigat√≥rias

#### 4.1 Programa de Testes (PT-BR)
```markdown
# Testes de Resili√™ncia e Business Continuity

## Programa Anual de Testes

### Tipos de Testes

#### Tabletop Exercises (TTX)
**Frequ√™ncia:** Trimestral  
**Dura√ß√£o:** 2-3 horas  
**Participantes:** CMT + stakeholders chave  
**Objetivo:** Validar procedimentos de crise e comunica√ß√£o

#### Simulation Drills (Simula√ß√µes)
**Frequ√™ncia:** Semestral  
**Dura√ß√£o:** 4-8 horas  
**Participantes:** Engineering + DevOps + Product  
**Objetivo:** Executar runbooks em ambiente controlado

#### Full DR Tests (Testes Completos)
**Frequ√™ncia:** Anual  
**Dura√ß√£o:** 1 dia (com rollback)  
**Participantes:** Toda organiza√ß√£o  
**Objetivo:** Failover real para DR region, validar RTOs/RPOs

---

### Calend√°rio de Testes 2025

| Data | Tipo | Escopo | Status |
|------|------|--------|--------|
| 2025-03-15 | Tabletop | Cyberattack response | ‚úÖ Conclu√≠do |
| 2025-06-10 | Simulation | RDS failover | ‚úÖ Conclu√≠do |
| 2025-09-20 | Full DR | Multi-region failover | üîÑ Planejado |
| 2025-12-05 | Tabletop | Crisis communication | üîÑ Planejado |
```

#### 4.2 Evid√™ncias de Testes Realizados
```markdown
## Evid√™ncias de Testes (√öltimos 12 Meses)

### Teste #1: Tabletop Exercise - Cyberattack Response

**Data:** 2025-03-15  
**Tipo:** Tabletop (TTX)  
**Dura√ß√£o:** 2.5 horas

**Cen√°rio:**
Ransomware detectado em servidor de aplica√ß√£o. Database potencialmente comprometido.

**Participantes:**
- CTO (Crisis Manager)
- CISO (Security Lead)
- DevOps Lead (Technical Lead)
- VP Customer Success (Communications Lead)
- Engineering Manager
- Legal Counsel

**Procedimentos Testados:**
- ‚úÖ Declara√ß√£o de crise e convoca√ß√£o do CMT
- ‚úÖ Isolamento de sistema comprometido
- ‚úÖ An√°lise forense e identifica√ß√£o de impacto
- ‚úÖ Comunica√ß√£o interna e externa
- ‚úÖ Decis√£o de restore de backup vs negocia√ß√£o

**Resultados:**
- **RTO Simulado:** 3.5 horas (meta: 4h) ‚úÖ
- **Comunica√ß√£o:** Todos stakeholders notificados em 45min ‚úÖ
- **Decision-making:** Aprova√ß√£o de restore de backup em 1h ‚úÖ

**Li√ß√µes Aprendidas:**
1. ‚úÖ **Melhoria:** Adicionar runbook espec√≠fico para ransomware
2. ‚úÖ **Melhoria:** Criar template pr√©-aprovado de comunica√ß√£o para clientes
3. ‚ùå **Gap:** Falta de seguro cyber (cobrir extors√£o)
4. ‚úÖ **A√ß√£o:** Contratado seguro cyber em 2025-04-01

**Evid√™ncias:**
- Ata de reuni√£o: `docs/tests/2025-03-15-ttx-cyberattack.pdf`
- Grava√ß√£o (parcial): `s3://bc-tests/2025-03-15-recording.mp4`
- Action items tracker: Jira Epic BCMS-123

---

### Teste #2: DR Simulation - Database Failover

**Data:** 2025-06-10  
**Tipo:** Simulation Drill (Hands-On)  
**Dura√ß√£o:** 6 horas (incluindo rollback)

**Cen√°rio:**
Primary AWS region (us-east-1) sofre outage prolongado. Necess√°rio failover para DR region (us-west-2).

**Participantes:**
- DevOps Lead (conduzindo)
- 3x SRE Engineers
- 2x Backend Engineers
- CTO (observador)

**Procedimentos Testados:**
- ‚úÖ Promo√ß√£o de RDS read replica para primary
- ‚úÖ Scaling de EKS cluster no DR region
- ‚úÖ DNS failover (Route53)
- ‚úÖ Smoke tests e valida√ß√£o
- ‚úÖ Rollback para regi√£o original

**Resultados:**
| M√©trica | Meta | Atingido | Status |
|---------|------|----------|--------|
| RTO | 2h | 2h 15min | ‚ö†Ô∏è Pr√≥ximo (aceit√°vel) |
| RPO | 1h | 45min | ‚úÖ Melhor que meta |
| Smoke tests | 100% pass | 100% pass | ‚úÖ |
| Rollback time | 1h | 55min | ‚úÖ |

**Issues Identificados:**
1. ‚ùå **Issue:** EKS scaling demorou 35min (esperado: 20min)
   - **Root Cause:** Insufficient warm nodes, cold start penalty
   - **Fix:** Aumentar min nodes de 2 para 5 no DR cluster
   - **Status:** ‚úÖ Implementado 2025-06-15

2. ‚ùå **Issue:** Smoke tests falharam inicialmente (Redis timeout)
   - **Root Cause:** ElastiCache n√£o estava pre-warmed no DR
   - **Fix:** Adicionar Redis ao warm standby (antes s√≥ database)
   - **Status:** ‚úÖ Implementado 2025-06-18

**Evid√™ncias:**
- Runbook executado: `docs/runbooks/dr-multi-region-failover.md`
- Logs t√©cnicos: `s3://bc-tests/2025-06-10-dr-simulation/`
- Screenshots: CloudWatch dashboards durante teste
- Post-mortem: Confluence page (link interno)

---

### Teste #3: Full DR Test (Planejado Setembro 2025)

**Data Planejada:** 2025-09-20  
**Tipo:** Full Disaster Recovery Test  
**Dura√ß√£o Estimada:** 1 dia completo

**Escopo:**
- Failover completo para DR region durante hor√°rio de baixo tr√°fego
- Executar tr√°fego real no DR por 4 horas
- Rollback para regi√£o prim√°ria
- Validar todos servi√ßos cr√≠ticos

**Prepara√ß√£o:**
- [ ] Comunicar clientes enterprise 2 semanas antes
- [ ] Atualizar status page com janela de manuten√ß√£o
- [ ] Treinar novos membros do time
- [ ] Revisar runbooks e automatizar passos manuais

**Aprova√ß√£o:** CTO + CEO (impacto potencial em clientes)
```

#### 4.3 Treinamentos de Resili√™ncia
```markdown
## Treinamentos Internos sobre Resili√™ncia

### Workshop #1: Introduction to Business Continuity

**Data:** 2025-02-20  
**Participantes:** 35 colaboradores (Engineering + Product + CS)  
**Dura√ß√£o:** 3 horas

**Conte√∫do:**
- Conceitos de BC/DR (RTO, RPO, BIA)
- Import√¢ncia de resili√™ncia para clientes
- Overview do BCP e DRP da empresa
- Pap√©is e responsabilidades durante crise
- Q&A

**Instrutor:** CTO + DevOps Lead

**Evid√™ncias:**
- Slides: `docs/training/2025-02-20-bc-intro.pdf`
- Attendance list: 35/40 presentes (87.5%)
- Feedback survey: 4.5/5 average rating
- Certificate: Emitido para todos participantes

---

### Onboarding BC/DR (Cont√≠nuo)

**Frequ√™ncia:** Toda nova contrata√ß√£o (Engineering)  
**Dura√ß√£o:** 1 hora  
**Formato:** 1:1 com DevOps Lead

**Checklist:**
- [ ] Explicar estrutura de on-call e PagerDuty
- [ ] Revisar runbooks de DR
- [ ] Mostrar dashboards de monitoramento
- [ ] Adicionar ao Slack #incident-response
- [ ] Dar acesso de emerg√™ncia (break-glass)

**Tracking:** 100% dos novos engineers completaram em 2025
```

### Guidelines de Conte√∫do
- **Idioma:** Resilience Testing (termo t√©cnico), relat√≥rios em PT-BR
- **CR√çTICO:** Manter evid√™ncias detalhadas (atas, logs, screenshots)
- **Atualiza√ß√£o:** Ap√≥s cada teste
- **Respons√°vel:** DevOps Lead

---

## 5. recovery-objectives.md

### Objetivo
Documentar Recovery Time Objectives (RTOs) e Recovery Point Objectives (RPOs) conforme ISO 22301:2019 Cl√°usula 8.2.3, estabelecendo toler√¢ncias de indisponibilidade e perda de dados.

**Responde:** ‚úÖ **Serasa Req #5** - "Pol√≠tica de backup/restaura√ß√£o: documenta√ß√£o baseada em objetivos de Tempo de Recupera√ß√£o (RTOs) e Objetivos de Ponto de Recupera√ß√£o (RPOs)"

### Se√ß√µes Obrigat√≥rias

#### 5.1 RTOs e RPOs Definidos (EN-US + PT-BR)
```markdown
# Recovery Objectives (RTOs/RPOs)

## Recovery Time Objectives (RTOs)

**Defini√ß√£o:** Tempo m√°ximo aceit√°vel de indisponibilidade de um processo ou sistema ap√≥s um incidente.

### RTOs por Processo Cr√≠tico

| Processo/Sistema | RTO | Justificativa | Estrat√©gia |
|------------------|-----|---------------|------------|
| **Processamento de Transa√ß√µes** | 1 hora | Impacto financeiro R$ 500K/h | Multi-AZ HA |
| **Autentica√ß√£o de Usu√°rios** | 30 minutos | Zero funcionalidade sem login | Auth0 SaaS 99.99% |
| **APIs Core de Integra√ß√£o** | 2 horas | SLAs contratuais (Serasa) | Multi-AZ + DR |
| **Analytics/Dashboards** | 8 horas | N√£o-cr√≠tico, reporting pode atrasar | Warm standby DR |
| **Admin/Backoffice** | 24 horas | Uso interno, workarounds manuais | Backup restore |

---

## Recovery Point Objectives (RPOs)

**Defini√ß√£o:** Perda m√°xima aceit√°vel de dados medida em tempo (dados desde √∫ltimo backup aceit√°vel).

### RPOs por Sistema de Dados

| Sistema | RPO | Justificativa | Mecanismo de Backup |
|---------|-----|---------------|---------------------|
| **Production Database** | 5 minutos | Zero perda de transa√ß√µes financeiras | RDS PITR (transaction logs) |
| **User Sessions (Redis)** | 1 segundo | Sess√µes podem ser recriadas rapidamente | Redis AOF (append-only file) |
| **Static Assets (S3)** | 0 (zero) | S3 versioning nativo | Versioning + cross-region repl |
| **Logs de Auditoria** | 0 (zero) | Compliance obriga logs imut√°veis | Immutable S3 buckets |
| **Analytics Data** | 4 horas | Pode ser reprocessado de raw data | Daily snapshots |
```

#### 5.2 Pol√≠tica de Backup e Restaura√ß√£o
```markdown
## Pol√≠tica de Backup e Restaura√ß√£o

### Automated Backup Policy

#### Production Database (PostgreSQL RDS)

**Backup Frequency:**
- **Full Snapshots:** Di√°rios √†s 02:00 UTC
- **Transaction Logs:** Cont√≠nuos (a cada 5 minutos)
- **Reten√ß√£o:** 30 dias (snapshots), 7 dias (transaction logs)

**RPO Alcan√ßado:** 5 minutos (via PITR)

**Restore Procedures:**
```bash
# PITR Restore (Point-in-Time Recovery)
aws rds restore-db-instance-to-point-in-time \
  --source-db-instance-identifier db-production-1 \
  --target-db-instance-identifier db-restored \
  --restore-time "2025-06-03T14:30:00Z"

# Tempo estimado: 30-60 minutos (depende do tamanho)
```

**Teste de Restore:** Semanal (automated)

---

#### Redis Cache/Sessions

**Backup Frequency:**
- **AOF (Append-Only File):** Cada write operation
- **RDB Snapshots:** A cada 1 hora
- **Reten√ß√£o:** 3 dias

**RPO Alcan√ßado:** 1 segundo (AOF)

**Restore Procedures:**
```bash
# Redis restore de AOF
redis-cli --rdb /backups/dump-2025-06-03.rdb
redis-cli BGREWRITEAOF

# Tempo estimado: 5-10 minutos
```

---

#### Object Storage (S3)

**Backup Strategy:**
- **Versioning:** Habilitado (all buckets)
- **Cross-Region Replication:** us-east-1 ‚Üí us-west-2
- **Lifecycle Policies:** 
  - Current versions: retained indefinitely
  - Non-current versions: deleted after 90 days
  - Glacier archiving: after 365 days (compliance logs)

**RPO Alcan√ßado:** 0 (versioning nativo)

**Restore Procedures:**
```bash
# Restore vers√£o espec√≠fica
aws s3api get-object \
  --bucket production-data \
  --key critical-file.json \
  --version-id "xyz123" \
  /tmp/restored-file.json

# Tempo estimado: Imediato (segundos)
```

---

#### Source Code (GitHub)

**Backup Strategy:**
- **Native Versioning:** Git history completo
- **Mirror Backup:** Replica√ß√£o di√°ria para GitLab (secondary provider)
- **Local Backups:** Weekly full clone to S3

**RPO Alcan√ßado:** 0 (git commit = backup)

---

### Backup Testing Schedule

| Tipo de Backup | Frequ√™ncia de Teste | √öltima Execu√ß√£o | Pr√≥ximo Teste |
|----------------|---------------------|-----------------|---------------|
| RDS PITR | Semanal | 2025-05-28 ‚úÖ | 2025-06-04 |
| RDS Full Snapshot | Mensal | 2025-05-15 ‚úÖ | 2025-06-15 |
| Redis Restore | Mensal | 2025-05-20 ‚úÖ | 2025-06-20 |
| S3 Version Restore | Trimestral | 2025-04-10 ‚úÖ | 2025-07-10 |

### Backup Validation Process

#### Automated Tests (Semanal)
```bash
#!/bin/bash
# Script: validate-backups.sh

# 1. Restore RDS snapshot to test instance
aws rds restore-db-instance-from-db-snapshot ...

# 2. Run data integrity checks
psql -h test-db -c "SELECT COUNT(*) FROM users" | grep "^[0-9]\+$"

# 3. Validate checksums
md5sum /backup/file.sql == stored_checksum

# 4. Cleanup test instance
aws rds delete-db-instance --db-instance-identifier test-db

# 5. Report results to #devops Slack
curl -X POST https://hooks.slack.com/services/xxx \
  -d '{"text":"‚úÖ Backup validation PASSED"}'
```

#### Manual Audits (Trimestral)
- Revisar logs de backup (falhas, avisos)
- Validar que reten√ß√£o policies est√£o corretas
- Confirmar que cross-region replication est√° funcionando
- Atualizar runbooks se necess√°rio

---

### Backup Security

#### Encryption
- **At Rest:** AES-256 (AWS KMS managed keys)
- **In Transit:** TLS 1.3 (all backup transfers)
- **Key Rotation:** Annual (KMS automatic)

#### Access Control
- **S3 Backup Buckets:** Apenas IAM roles autorizadas
- **RDS Snapshots:** Encrypted, n√£o-p√∫blicos
- **Audit Logs:** CloudTrail tracking de todos acessos a backups

#### Retention Compliance
- **LGPD:** Dados pessoais deleted after 2 anos (unless legal basis)
- **Audit Logs:** Retained for 7 anos (compliance requirement)
- **Backup Lifecycle:** Automated deletion ap√≥s per√≠odo de reten√ß√£o
```

#### 5.3 SLA de Backup e Restore
```markdown
## Service Level Agreements (SLAs) - Backup e Restore

### Backup SLAs

| M√©trica | SLA | Atual (3 meses) | Status |
|---------|-----|-----------------|--------|
| **Backup Success Rate** | > 99.5% | 99.8% | ‚úÖ |
| **Backup Completion Time** | < 2 horas | 1.2h avg | ‚úÖ |
| **Cross-Region Replication Lag** | < 15 minutos | 8 min avg | ‚úÖ |
| **Backup Validation Pass Rate** | 100% | 100% | ‚úÖ |

### Restore SLAs

| Sistema | RTO SLA | RPO SLA | √öltimo Teste | Status |
|---------|---------|---------|--------------|--------|
| Production DB | 1 hora | 5 minutos | 2025-05-28 (55min) | ‚úÖ |
| Redis Cache | 30 minutos | 1 segundo | 2025-05-20 (22min) | ‚úÖ |
| S3 Objects | Imediato | 0 | 2025-04-10 (<1min) | ‚úÖ |
| Full Infrastructure | 2 horas | 1 hora | 2025-06-10 (2h 15min) | ‚ö†Ô∏è |

**Nota:** Full Infrastructure RTO foi 2h 15min (15min above SLA) no √∫ltimo teste (2025-06-10). Melhorias implementadas: aumentar warm standby capacity no DR region. Pr√≥ximo teste: 2025-09-20.
```

### Guidelines de Conte√∫do
- **Idioma:** RTO, RPO (termos t√©cnicos), explica√ß√µes em PT-BR
- **CR√çTICO:** RTOs/RPOs devem ser realistas e testados
- **Atualiza√ß√£o:** Anual ou quando houver mudan√ßa de infraestrutura
- **Respons√°vel:** DevOps Lead + CTO

---

## Certification Readiness Checklist (ISO 22301)

Para prepara√ß√£o para certifica√ß√£o ISO 22301:

- [ ] Todos os 5 documentos obrigat√≥rios criados e atualizados
- [ ] Business Impact Analysis (BIA) completo
- [ ] RTOs/RPOs definidos e validados
- [ ] BCP e DRP testados nos √∫ltimos 12 meses
- [ ] Evid√™ncias de testes documentadas (atas, relat√≥rios, logs)
- [ ] Treinamentos de resili√™ncia completados (>80% do time)
- [ ] Crisis Management Team definido e treinado
- [ ] Canais de comunica√ß√£o de crise testados
- [ ] Exerc√≠cio anual de DR executado
- [ ] Backups testados regularmente (evid√™ncias)
- [ ] Management review conduzida
- [ ] Non-conformities corrigidas

---

## Cross-References com Outros Frameworks

### ISO 22301 ‚Üî ISO 27001
- ISO 22301 Incident Management ‚Üí ISO 27001 Security Incident Response
- ISO 22301 RTO/RPO ‚Üí ISO 27001 Availability Controls
- **Estrat√©gia:** Documentos separados com cross-references

### ISO 22301 ‚Üî SOC2
- ISO 22301 Availability ‚Üí SOC2 Availability Criteria
- ISO 22301 Backup/Restore ‚Üí SOC2 Backup Controls
- **Estrat√©gia:** SOC2 pode referenciar ISO 22301 como evid√™ncia

---

**√öltima Atualiza√ß√£o do Template:** 2025-06-03  
**Vers√£o:** 1.0 (ISO 22301:2019)  
**Mantido por:** @iso-22301-specialist  
**CR√çTICO:** ‚úÖ Mapeia 5/8 requisitos Serasa Experian

