---
title: "Matriz de Risco de IA"
version: "1.0"
last_update: "[DD/MM/YYYY]"
next_review: "[DD/MM/YYYY]"
owner: "Comit√™ de IA"
classification: "CONFIDENCIAL - USO INTERNO"
---

# Matriz de Risco de IA

**GRANAAI - INFRATECH DE RECEB√çVEIS**

> **Objetivo:** Identificar, avaliar e gerenciar riscos associados ao desenvolvimento e uso de sistemas de Intelig√™ncia Artificial, garantindo governan√ßa respons√°vel e mitiga√ß√£o proativa.

---

## üìã Metodologia

### Framework Base

**Esta matriz segue:**
- **NIST AI Risk Management Framework (AI RMF 1.0)**
- **ISO 31000:2018** (Gest√£o de Riscos)
- **AI Governance Policy do Granaai**

**Refer√™ncias:**
- [NIST AI RMF](https://www.nist.gov/itl/ai-risk-management-framework)
- [AI Governance Policy](../../ai-governance/ai-governance-policy.md)

---

### Escala de Avalia√ß√£o

#### **Probabilidade:**

| N√≠vel | Descri√ß√£o | Frequ√™ncia Esperada |
|-------|-----------|---------------------|
| **Baixa** | Improv√°vel de ocorrer | < 1 vez/ano |
| **M√©dia** | Pode ocorrer eventualmente | 1-4 vezes/ano |
| **Alta** | Prov√°vel de ocorrer | > 4 vezes/ano |

#### **Impacto:**

| N√≠vel | Descri√ß√£o | Consequ√™ncias |
|-------|-----------|---------------|
| **Baixo** | Impacto m√≠nimo | Sem danos significativos, resolu√ß√£o r√°pida |
| **M√©dio** | Impacto moderado | Requer aten√ß√£o, pode afetar poucos usu√°rios |
| **Alto** | Impacto cr√≠tico | Afeta muitos usu√°rios, danos reputacionais/financeiros |

#### **N√≠vel de Risco (Probabilidade √ó Impacto):**

| Probabilidade | Impacto Baixo | Impacto M√©dio | Impacto Alto |
|---------------|---------------|---------------|--------------|
| **Alta** | üü° M√©dio | üî¥ Alto | üî¥ Cr√≠tico |
| **M√©dia** | üü¢ Baixo | üü° M√©dio | üî¥ Alto |
| **Baixa** | üü¢ Baixo | üü¢ Baixo | üü° M√©dio |

**Legenda:**
- üü¢ **Verde:** Risco aceit√°vel (monitoramento padr√£o)
- üü° **Amarelo:** Risco m√©dio (mitiga√ß√£o necess√°ria)
- üî¥ **Vermelho:** Risco alto (a√ß√£o urgente obrigat√≥ria)

---

## üìä Matriz de Riscos de IA

### **CATEGORIA 1: RISCOS T√âCNICOS**

#### 1.1 Degrada√ß√£o de Performance (Drift)

**Descri√ß√£o:** Performance do modelo degrada ao longo do tempo devido a mudan√ßas nos dados de entrada ou contexto operacional.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | M√©dia |
| **Impacto** | M√©dio |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- Accuracy cai abaixo de 85%
- User Satisfaction cai abaixo de 4.0/5.0
- Escalation Rate aumenta acima de 30%

**Controles Atuais:**
-  Monitoramento trimestral de KPIs
-  Compara√ß√£o com baseline (GPT-4-2023-11)
-  Alertas automatizados se thresholds cr√≠ticos

**Plano de Mitiga√ß√£o:**
- [ ] Implementar detec√ß√£o autom√°tica de drift (mensal)
- [ ] Estabelecer processo de retraining/atualiza√ß√£o (se modelo propriet√°rio)
- [ ] Avaliar upgrade de vers√£o de modelo (ex: GPT-4 ‚Üí GPT-4-Turbo)

**Respons√°vel:** AI Engineer  
**Prazo:** Q2/2025

**Risco Residual:** üü¢ Baixo (ap√≥s mitiga√ß√£o)

---

#### 1.2 Falha de Modelo em Produ√ß√£o

**Descri√ß√£o:** Modelo apresenta erro cr√≠tico, causando indisponibilidade ou respostas incorretas em massa.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | Baixa |
| **Impacto** | Alto |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- Erro rate > 5%
- Downtime > 5 minutos
- Usu√°rios reportam comportamento anormal

**Controles Atuais:**
-  Testing obrigat√≥rio em staging (1 semana)
-  Rollback plan documentado para cada modelo
-  Monitoramento CloudWatch (alertas em tempo real)
-  Incident response team on-call

**Plano de Mitiga√ß√£o:**
-  Processo de rollback < 10 minutos
-  Backup de modelo anterior (fallback)
-  Circuit breaker (desabilitar automaticamente se error rate alto)

**Respons√°vel:** AI Engineer + CTO  
**Prazo:** Implementado

**Risco Residual:** üü¢ Baixo

---

#### 1.3 Depend√™ncia de Vendor √önico (OpenAI)

**Descri√ß√£o:** Depend√™ncia cr√≠tica de um √∫nico vendor (OpenAI) para GPT-4, sem alternativa de backup.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | M√©dia |
| **Impacto** | Alto |
| **N√≠vel de Risco** | üî¥ **Alto** |

**Indicadores:**
- OpenAI com downtime frequente
- Mudan√ßa abrupta de pricing
- Descontinua√ß√£o de vers√£o do modelo

**Controles Atuais:**
-  SLA de 99.9% com OpenAI
-  Monitoramento de uptime
- ‚ö†Ô∏è Sem vendor alternativo implementado

**Plano de Mitiga√ß√£o:**
- [ ] Avaliar vendors alternativos (Anthropic Claude, Google Gemini, Azure OpenAI)
- [ ] Implementar architecture agn√≥stica (f√°cil troca de vendor)
- [ ] Estabelecer contrato de backup com vendor secund√°rio
- [ ] Desenvolver modelo propriet√°rio (longo prazo)

**Respons√°vel:** CTO + AI Engineer  
**Prazo:** Q3/2025 (avalia√ß√£o) | Q4/2025 (implementa√ß√£o backup)

**Risco Residual:** üü° M√©dio (ap√≥s mitiga√ß√£o)

---

#### 1.4 Lat√™ncia Elevada (Response Time)

**Descri√ß√£o:** Tempo de resposta do modelo excede limites aceit√°veis, prejudicando experi√™ncia do usu√°rio.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | Baixa |
| **Impacto** | M√©dio |
| **N√≠vel de Risco** | üü¢ **Baixo** |

**Indicadores:**
- Response Time p95 > 3 segundos
- User complaints sobre lentid√£o

**Controles Atuais:**
-  Target p95 < 3s monitorado trimestralmente
-  Caching de respostas frequentes
-  Otimiza√ß√£o de prompts

**Plano de Mitiga√ß√£o:**
- [ ] Implementar CDN para assets est√°ticos
- [ ] Avaliar modelo mais r√°pido (ex: GPT-3.5-Turbo para casos simples)
- [ ] Otimizar knowledge base (reduzir tokens)

**Respons√°vel:** AI Engineer  
**Prazo:** Sob demanda (se p95 > 3s)

**Risco Residual:** üü¢ Baixo

---

### **CATEGORIA 2: RISCOS √âTICOS**

#### 2.1 Vi√©s e Discrimina√ß√£o

**Descri√ß√£o:** Modelo apresenta vi√©s sistem√°tico baseado em g√™nero, ra√ßa, idade ou outras caracter√≠sticas protegidas.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | M√©dia |
| **Impacto** | Alto |
| **N√≠vel de Risco** | üî¥ **Alto** |

**Indicadores:**
- Bias incidents > 0
- User reports de discrimina√ß√£o
- Automated bias detection com alertas frequentes

**Controles Atuais:**
-  Revis√£o Humana Semanal (100 conversas)
-  Automated Bias Detection (di√°rio)
-  Red Team Testing (mensal)
-  Prompts ajustados para neutralidade
-  Output validation (filtro de vi√©s)

**Base:** [AI Governance Policy - Mitiga√ß√£o de Vi√©s](../../ai-governance/ai-governance-policy.md#mitiga√ß√£o-de-vi√©s-e-comportamentos-indesejados)

**Plano de Mitiga√ß√£o:**
-  Processo de monitoramento robusto (implementado)
- [ ] Expandir Red Team scenarios (incluir mais categorias)
- [ ] Treinamento de equipe CS sobre identifica√ß√£o de vi√©s
- [ ] Implementar fairness metrics automatizadas

**Respons√°vel:** AI Engineer + QA Lead  
**Prazo:** Q2/2025 (expans√£o de testes)

**Risco Residual:** üü° M√©dio (ap√≥s mitiga√ß√£o)

---

#### 2.2 Falta de Transpar√™ncia (Black Box)

**Descri√ß√£o:** Decis√µes do modelo n√£o s√£o explic√°veis, dificultando auditoria e confian√ßa dos usu√°rios.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | Alta |
| **Impacto** | M√©dio |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- Usu√°rios questionam "como a IA chegou a essa resposta?"
- Impossibilidade de auditar decis√µes espec√≠ficas

**Controles Atuais:**
-  RAG pattern (Retrieval-Augmented Generation) - fontes citadas
-  Logs de auditoria (contexto da resposta registrado)
-  Knowledge base documentada

**Plano de Mitiga√ß√£o:**
-  RAG j√° implementado (mitiga√ß√£o principal)
- [ ] Melhorar cita√ß√£o de fontes nas respostas (mais expl√≠cita)
- [ ] Implementar "explain this answer" feature (usu√°rio pode solicitar detalhes)

**Respons√°vel:** Product Manager + AI Engineer  
**Prazo:** Q3/2025

**Risco Residual:** üü¢ Baixo (ap√≥s mitiga√ß√£o)

---

#### 2.3 Comportamento Inadequado ou Prejudicial

**Descri√ß√£o:** Modelo gera respostas ofensivas, prejudiciais ou inapropriadas.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | Baixa |
| **Impacto** | Alto |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- User reports de respostas inadequadas
- Support Agent flags
- Automated content safety alerts

**Controles Atuais:**
-  Azure Content Safety API (filtro de conte√∫do sens√≠vel)
-  Output validation (tone check)
-  Prompts com instru√ß√µes de profissionalismo
-  User feedback (thumbs down)

**Base:** [AI Governance Policy - Guardrails](../../ai-governance/ai-governance-policy.md#guardrails-implementados)

**Plano de Mitiga√ß√£o:**
-  Guardrails robustos (implementados)
- [ ] Expandir lista de keywords bloqueados
- [ ] Implementar sentiment analysis mais sofisticado

**Respons√°vel:** AI Engineer  
**Prazo:** Cont√≠nuo

**Risco Residual:** üü¢ Baixo

---

### **CATEGORIA 3: RISCOS REGULAT√ìRIOS**

#### 3.1 N√£o Conformidade com LGPD

**Descri√ß√£o:** Viola√ß√£o da LGPD por processamento inadequado de dados pessoais ou falta de transpar√™ncia.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | Baixa |
| **Impacto** | Alto |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- Reclama√ß√£o √† ANPD
- Auditoria LGPD identifica n√£o conformidades
- Dados pessoais vazados ou processados indevidamente

**Controles Atuais:**
-  Conversas N√ÉO armazenadas (apenas metadados)
-  Reten√ß√£o limitada (90 dias)
-  Disclaimer de IA para usu√°rios (transpar√™ncia)
-  Opt-out dispon√≠vel (escalar para humano)
-  Direitos dos titulares implementados
-  DPO revisou e aprovou

**Base:** [AI Governance Policy - Compliance LGPD](../../ai-governance/ai-governance-policy.md#compliance-com-lgpd)

**Plano de Mitiga√ß√£o:**
-  Compliance robusto (implementado)
- [ ] Auditoria LGPD anual (externa)
- [ ] Treinamento cont√≠nuo de equipe sobre LGPD

**Respons√°vel:** CISO / DPO  
**Prazo:** Anual (auditoria)

**Risco Residual:** üü¢ Baixo

---

#### 3.2 Futuras Regula√ß√µes de IA (EU AI Act, etc.)

**Descri√ß√£o:** Novas regula√ß√µes de IA podem exigir compliance adicional, gerando custos e atrasos.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | M√©dia |
| **Impacto** | M√©dio |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- EU AI Act ou regula√ß√£o brasileira de IA aprovada
- Requisitos de conformidade n√£o atendidos

**Controles Atuais:**
-  Monitoramento cont√≠nuo de regula√ß√µes emergentes
-  Documenta√ß√£o t√©cnica robusta (facilitar√° compliance)
-  Processo de governan√ßa estruturado (Comit√™ IA)

**Plano de Mitiga√ß√£o:**
- [ ] Acompanhar tramita√ß√£o de regula√ß√µes
- [ ] Preparar documenta√ß√£o t√©cnica conforme draft EU AI Act
- [ ] Realizar gap analysis quando regula√ß√£o for aprovada

**Respons√°vel:** CISO + Jur√≠dico  
**Prazo:** Cont√≠nuo

**Risco Residual:** üü° M√©dio

---

#### 3.3 Responsabilidade Civil por Decis√µes de IA

**Descri√ß√£o:** Granaai pode ser responsabilizada civilmente por decis√µes incorretas ou prejudiciais da IA.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | Baixa |
| **Impacto** | Alto |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- Usu√°rio sofre dano por seguir recomenda√ß√£o incorreta da IA
- Processo judicial

**Controles Atuais:**
-  Disclaimer: IA √© assistente, decis√µes finais s√£o humanas
-  Escalation para humano sempre dispon√≠vel
-  ChatBot limitado a N√≠vel 1 (sem decis√µes cr√≠ticas)
-  Logs de auditoria (rastreabilidade)

**Plano de Mitiga√ß√£o:**
-  Disclaimers e limita√ß√µes claras (implementado)
- [ ] Seguro de responsabilidade civil (cyber insurance)
- [ ] Revis√£o de Termos de Uso (cl√°usula sobre IA)

**Respons√°vel:** Jur√≠dico + CEO  
**Prazo:** Q2/2025 (seguro)

**Risco Residual:** üü¢ Baixo (ap√≥s mitiga√ß√£o)

---

### **CATEGORIA 4: RISCOS REPUTACIONAIS**

#### 4.1 Incidente P√∫blico de IA

**Descri√ß√£o:** Incidente de IA (vi√©s, erro grave, vazamento) torna-se p√∫blico, danificando reputa√ß√£o da Granaai.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | Baixa |
| **Impacto** | Alto |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- Not√≠cia negativa em m√≠dia
- Viraliza√ß√£o negativa em redes sociais
- Perda de clientes

**Controles Atuais:**
-  Governan√ßa robusta (Comit√™ IA)
-  Monitoramento cont√≠nuo (bias, security)
-  Incident response plan
-  Comunica√ß√£o transparente (princ√≠pio)

**Plano de Mitiga√ß√£o:**
-  Processos preventivos (implementados)
- [ ] Media training para CEO/CMO (comunica√ß√£o de crise IA)
- [ ] Plano de comunica√ß√£o de crise (espec√≠fico para IA)
- [ ] Simula√ß√£o de incidente p√∫blico (tabletop exercise)

**Respons√°vel:** CMO + CEO + CISO  
**Prazo:** Q3/2025

**Risco Residual:** üü¢ Baixo (ap√≥s mitiga√ß√£o)

---

#### 4.2 Perda de Confian√ßa dos Usu√°rios

**Descri√ß√£o:** Usu√°rios perdem confian√ßa na IA devido a experi√™ncias negativas (respostas ruins, vi√©s percebido).

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | M√©dia |
| **Impacto** | M√©dio |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- User Satisfaction < 4.0/5.0
- Aumento de thumbs down
- Usu√°rios optam por atendimento humano sistematicamente

**Controles Atuais:**
-  Monitoramento de User Satisfaction (trimestral)
-  Feedback loop (thumbs up/down)
-  Melhorias cont√≠nuas baseadas em feedback

**Plano de Mitiga√ß√£o:**
-  Processo de melhoria cont√≠nua (implementado)
- [ ] Comunica√ß√£o proativa sobre melhorias de IA
- [ ] Educar usu√°rios sobre capacidades e limita√ß√µes da IA

**Respons√°vel:** Product Manager + CS  
**Prazo:** Cont√≠nuo

**Risco Residual:** üü¢ Baixo

---

### **CATEGORIA 5: RISCOS OPERACIONAIS**

#### 5.1 Downtime do Vendor (OpenAI)

**Descri√ß√£o:** OpenAI apresenta indisponibilidade prolongada, impactando opera√ß√£o do ChatBot.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | M√©dia |
| **Impacto** | M√©dio |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- OpenAI uptime < 99.9%
- Downtime > 15 minutos
- Usu√°rios n√£o conseguem usar ChatBot

**Controles Atuais:**
-  SLA de 99.9% com OpenAI
-  Monitoramento de uptime (CloudWatch)
-  Fallback para atendimento humano
- ‚ö†Ô∏è Sem vendor alternativo

**Base:** [AI Governance Policy - Vendor Management](../../ai-governance/ai-governance-policy.md#governan√ßa-de-modelos)

**Plano de Mitiga√ß√£o:**
- [ ] Implementar vendor secund√°rio (backup)
- [ ] Mensagem clara aos usu√°rios em caso de downtime
- [ ] Queue para atendimento humano automatizado

**Respons√°vel:** CTO + AI Engineer  
**Prazo:** Q4/2025

**Risco Residual:** üü° M√©dio (at√© implementar backup)

---

#### 5.2 Custo Elevado de Opera√ß√£o

**Descri√ß√£o:** Custo de opera√ß√£o da IA (tokens, infraestrutura) excede or√ßamento planejado.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | M√©dia |
| **Impacto** | Baixo |
| **N√≠vel de Risco** | üü¢ **Baixo** |

**Indicadores:**
- Custo/m√™s > or√ßamento em >20%
- Crescimento descontrolado de uso

**Controles Atuais:**
-  Monitoramento de custos (AWS Cost Explorer)
-  Rate limiting (prote√ß√£o contra abuse)
-  Otimiza√ß√£o de prompts (reduzir tokens)

**Plano de Mitiga√ß√£o:**
-  Controles implementados
- [ ] Estabelecer budget alerts (AWS)
- [ ] Renegociar contrato com OpenAI (volume discount)

**Respons√°vel:** CFO + CTO  
**Prazo:** Q2/2025

**Risco Residual:** üü¢ Baixo

---

#### 5.3 Falta de Expertise Interna

**Descri√ß√£o:** Perda de AI Engineer ou falta de conhecimento t√©cnico interno para gerenciar IA.

| Atributo | Valor |
|----------|-------|
| **Probabilidade** | M√©dia |
| **Impacto** | M√©dio |
| **N√≠vel de Risco** | üü° **M√©dio** |

**Indicadores:**
- Turnover de AI Engineer
- Dificuldade em resolver incidentes t√©cnicos

**Controles Atuais:**
- ‚ö†Ô∏è Expertise concentrada em 1-2 pessoas
-  Documenta√ß√£o t√©cnica robusta

**Plano de Mitiga√ß√£o:**
- [ ] Contratar AI Engineer adicional (redund√¢ncia)
- [ ] Treinamento cruzado (Product Manager, TI)
- [ ] Documentar runbooks detalhados
- [ ] Contrato de consultoria externa (backup)

**Respons√°vel:** CTO + RH  
**Prazo:** Q3/2025

**Risco Residual:** üü¢ Baixo (ap√≥s mitiga√ß√£o)

---

## üìä Dashboard de Riscos

### Resumo por Severidade

| N√≠vel | Quantidade | % | A√ß√£o |
|-------|-----------|---|------|
| üî¥ **Alto** | 2 | 13% | Mitiga√ß√£o priorit√°ria |
| üü° **M√©dio** | 11 | 73% | Planos de mitiga√ß√£o definidos |
| üü¢ **Baixo** | 2 | 14% | Monitoramento padr√£o |
| **Total** | **15** | **100%** | |

---

### Riscos Cr√≠ticos (Prioridade M√°xima)

| # | Risco | Severidade | Prazo de Mitiga√ß√£o | Respons√°vel |
|---|-------|-----------|-------------------|-------------|
| 1 | Vi√©s e Discrimina√ß√£o | üî¥ Alto | Q2/2025 | AI Engineer |
| 2 | Depend√™ncia de Vendor √önico | üî¥ Alto | Q4/2025 | CTO |

---

### Riscos Residuais Aceit√°veis (Ap√≥s Mitiga√ß√£o)

| Risco | Severidade Original | Severidade Residual | Justificativa |
|-------|-------------------|-------------------|---------------|
| Degrada√ß√£o de Performance | üü° M√©dio | üü¢ Baixo | Monitoramento trimestral robusto |
| Falha de Modelo | üü° M√©dio | üü¢ Baixo | Rollback plan < 10min |
| N√£o Conformidade LGPD | üü° M√©dio | üü¢ Baixo | Compliance implementado + DPO |

---

## üîÑ Revis√£o e Atualiza√ß√£o

### Periodicidade de Revis√£o

**Esta matriz deve ser revisada:**
- **Trimestralmente:** Pelo Comit√™ de IA (reuni√µes ordin√°rias)
- **Sob Demanda:** Quando novo risco identificado ou incidente ocorrer
- **Anualmente:** Revis√£o completa com ajuste de metodologia

**√öltima Revis√£o:** [DD/MM/YYYY]  
**Pr√≥xima Revis√£o:** [DD/MM/YYYY] (Trimestral)

---

### Processo de Atualiza√ß√£o

**Quando adicionar novo risco:**
1. Identificar risco (fonte: incidente, auditoria, nova regula√ß√£o, etc.)
2. Avaliar probabilidade e impacto
3. Determinar n√≠vel de risco
4. Definir plano de mitiga√ß√£o
5. Submeter ao Comit√™ de IA para aprova√ß√£o
6. Atualizar vers√£o da matriz

**Respons√°vel:** AI Engineer (proposta) + Comit√™ de IA (aprova√ß√£o)

---

## üìù Hist√≥rico de Vers√µes

| Vers√£o | Data | Mudan√ßas | Aprovado por |
|--------|------|----------|--------------|
| 1.0 | 06/10/2025 | Vers√£o inicial | Comit√™ de IA |
| | | | |

---

## üîó Refer√™ncias

- [Regimento do Comit√™ de IA](./regimento-comite-ia.md)
- [AI Governance Policy](../../ai-governance/ai-governance-policy.md)
- [Formul√°rio de Aprova√ß√£o de Modelo IA](./formulario-aprovacao-modelo-ia.md)
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
- [ISO 31000:2018 - Risk Management](https://www.iso.org/iso-31000-risk-management.html)

---

**üîê Classifica√ß√£o:** CONFIDENCIAL - USO INTERNO  
**üìÇ Reten√ß√£o:** Permanente (hist√≥rico de vers√µes)  
**üîÑ Vers√£o:** 1.0  
**üìÖ Data:** 2025-10-06
