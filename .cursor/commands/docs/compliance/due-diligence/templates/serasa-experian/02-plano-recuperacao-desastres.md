---
title: "Plano de Recupera√ß√£o de Desastres (PRD/DRP)"
document_type: "Plano"
classification: "CONFIDENCIAL - USO INTERNO"
version: "1.0"
date: "[DATA]"
owner: "[CTO/DevOps Lead]"
review_frequency: "Semestral"
iso_compliance: "ISO 22301:2019, ISO 27001:2022"
---

# Plano de Recupera√ß√£o de Desastres (PRD/DRP)

## üìã Controle de Vers√£o

| Vers√£o | Data | Autor | Descri√ß√£o | Aprovador |
|--------|------|-------|-----------|-----------|
| 1.0 | [DATA] | [NOME - DevOps Lead] | Vers√£o inicial do PRD | [NOME - CTO] |
| 1.1 | [DATA] | [NOME - DevOps Lead] | [DESCRI√á√ÉO DAS MUDAN√áAS] | [NOME - CTO] |

---

## üìÑ Sum√°rio Executivo

Este Plano de Recupera√ß√£o de Desastres (PRD) define os procedimentos t√©cnicos, recursos e responsabilidades necess√°rios para restaurar a infraestrutura tecnol√≥gica de **[NOME DA EMPRESA]** em caso de desastres que causem indisponibilidade total ou parcial dos sistemas cr√≠ticos.

O PRD est√° alinhado com o **[Plano de Continuidade de Neg√≥cios (BCP)](01-plano-continuidade-negocios.md)** e garante o cumprimento dos seguintes objetivos:

| M√©trica | Valor Contratual | Valor Testado | Status |
|---------|------------------|---------------|--------|
| **RTO (Recovery Time Objective)** | ‚â§ 2 horas | [X.X] horas | ‚úÖ Conforme |
| **RPO (Recovery Point Objective)** | ‚â§ 15 minutos | [X] minutos | ‚úÖ Conforme |
| **Disponibilidade Anual** | ‚â• 99.9% | [XX.XX]% | ‚úÖ Conforme |

**√öltima Atualiza√ß√£o:** [DATA]  
**Pr√≥ximo Teste Completo:** [DATA]  
**Conformidade:** ISO 22301:2019, ISO 27001:2022, SOC 2 (Availability)

---

## üéØ 1. Escopo Tecnol√≥gico

### 1.1 Infraestrutura Cr√≠tica

Este PRD cobre os seguintes componentes de infraestrutura:

#### 1.1.1 Servidores e Compute

| Componente | Tecnologia | Localiza√ß√£o Prim√°ria | Localiza√ß√£o DR | Criticidade |
|------------|-----------|---------------------|---------------|-------------|
| **API Backend** | AWS EKS (Kubernetes) | us-east-1 | us-west-2 | Cr√≠tica |
| **Banco de Dados Transacional** | AWS RDS PostgreSQL 14 | us-east-1 (Multi-AZ) | us-west-2 (Read Replica) | Cr√≠tica |
| **Cache / Session Store** | AWS ElastiCache Redis | us-east-1 | us-west-2 | Alta |
| **Autentica√ß√£o / OAuth** | AWS EC2 (Keycloak) | us-east-1 | us-west-2 | Cr√≠tica |
| **Background Jobs** | AWS ECS (Fargate) | us-east-1 | us-west-2 | Alta |
| **Admin Panel** | AWS S3 + CloudFront | us-east-1 | us-west-2 (replicado) | M√©dia |

#### 1.1.2 Redes e Conectividade

| Componente | Tecnologia | Redund√¢ncia | Criticidade |
|------------|-----------|-------------|-------------|
| **Load Balancer** | AWS ALB (Application Load Balancer) | Multi-AZ | Cr√≠tica |
| **DNS** | AWS Route53 (Geo-routing + Health Checks) | Global | Cr√≠tica |
| **VPN** | AWS VPN + Transit Gateway | Multi-AZ | Alta |
| **CDN** | AWS CloudFront | Global (Edge Locations) | Alta |
| **WAF** | AWS WAF | Global | Alta |

#### 1.1.3 Armazenamento e Dados

| Componente | Tecnologia | Replica√ß√£o | RPO | Criticidade |
|------------|-----------|-----------|-----|-------------|
| **Object Storage** | AWS S3 (Standard) | Cross-Region Replication | 0 (versionamento) | Cr√≠tica |
| **Backups RDS** | AWS Backup | Cross-Region (us-west-2) | 15 minutos | Cr√≠tica |
| **Logs de Aplica√ß√£o** | AWS CloudWatch Logs | us-east-1 | Alta |
| **Logs de Auditoria** | AWS S3 (Glacier) | Cross-Region | M√©dia |

### 1.2 Depend√™ncias Tecnol√≥gicas do Contrato Serasa

**Servi√ßos espec√≠ficos fornecidos √† Serasa Experian:**

1. **API de Consulta de Cr√©dito** (`/api/v1/credit-check`)
   - RTO: 1 hora
   - RPO: 15 minutos
   - Tr√°fego m√©dio: 1.000 req/min

2. **API de Valida√ß√£o de Documentos** (`/api/v1/document-validation`)
   - RTO: 2 horas
   - RPO: 15 minutos
   - Tr√°fego m√©dio: 500 req/min

3. **Webhook de Notifica√ß√µes** (`/webhooks/serasa/notifications`)
   - RTO: 4 horas
   - RPO: 30 minutos
   - Tr√°fego m√©dio: 100 req/min

**Depend√™ncias Externas:**
- AWS Cloud (provedor de infraestrutura prim√°rio)
- [ISP Principal] (conectividade fibra)
- [ISP Backup] (conectividade 4G/5G failover)
- [Outros Fornecedores Cr√≠ticos - ex: GitHub, etc.]

**Nota:** Serasa Experian √© um **CLIENTE** que consome nossas APIs, n√£o uma depend√™ncia externa.

---

## üìä 2. Objetivos de Recupera√ß√£o

### 2.1 RTO (Recovery Time Objective) por Sistema

Tempo m√°ximo toler√°vel para restaurar cada sistema ap√≥s um desastre:

| Sistema / Aplica√ß√£o | RTO Contratual | RTO Alcan√ßado (√öltimo Teste) | Prioridade de Recupera√ß√£o |
|---------------------|----------------|------------------------------|--------------------------|
| **1. Autentica√ß√£o (Keycloak)** | 30 min | [XX] min | üî¥ P1 - Cr√≠tica |
| **2. Banco de Dados (RDS)** | 1 hora | [XX] min | üî¥ P1 - Cr√≠tica |
| **3. APIs Backend (EKS)** | 1 hora | [XX] min | üî¥ P1 - Cr√≠tica |
| **4. Cache (ElastiCache)** | 2 horas | [XX] min | üü° P2 - Alta |
| **5. Background Jobs (ECS)** | 4 horas | [X] horas | üü° P2 - Alta |
| **6. Admin Panel (S3+CF)** | 8 horas | [X] horas | üü¢ P3 - M√©dia |
| **7. Monitoring (CloudWatch)** | 1 hora | [XX] min | üü° P2 - Alta |

**Ordem de Restaura√ß√£o:** P1 ‚Üí P2 ‚Üí P3

### 2.2 RPO (Recovery Point Objective) por Aplica√ß√£o

Perda m√°xima de dados aceit√°vel:

| Tipo de Dado | RPO Contratual | Estrat√©gia de Backup | Frequ√™ncia | √öltima Valida√ß√£o |
|--------------|----------------|---------------------|-----------|------------------|
| **Transa√ß√µes Financeiras** | 5 min | RDS Automated Backup + WAL | Cont√≠nuo | [DATA] |
| **Dados de Clientes (PII)** | 15 min | RDS Automated Backup | A cada 15 min | [DATA] |
| **Sess√µes de Usu√°rio** | 30 min | Redis AOF (Append-Only File) | A cada 1 min | [DATA] |
| **Arquivos Uploadados** | 0 (zero) | S3 Versioning + CRR | S√≠ncrono | [DATA] |
| **Logs de Aplica√ß√£o** | 1 hora | CloudWatch + S3 export | A cada 1 hora | [DATA] |
| **Configura√ß√µes (AWS Config)** | N/A | AWS Config Snapshots | Cont√≠nuo | [DATA] |

**Refer√™ncia:** Ver [Pol√≠tica de Backup e Restaura√ß√£o](06-politica-backup-restauracao.md) para detalhes completos.

### 2.3 Matriz de Criticidade de Sistemas

```mermaid
graph TD
    subgraph Criticidade_Critica[üî¥ Criticidade Cr√≠tica - RTO ‚â§ 1h]
        Auth[Autentica√ß√£o<br/>RTO: 30min]
        DB[Banco de Dados<br/>RTO: 1h]
        API[APIs Backend<br/>RTO: 1h]
        DNS[DNS/Route53<br/>RTO: 30min]
    end
    
    subgraph Criticidade_Alta[üü° Criticidade Alta - RTO ‚â§ 4h]
        Cache[ElastiCache<br/>RTO: 2h]
        Jobs[Background Jobs<br/>RTO: 4h]
        Monitor[Monitoring<br/>RTO: 1h]
        LB[Load Balancer<br/>RTO: 1h]
    end
    
    subgraph Criticidade_Media[üü¢ Criticidade M√©dia - RTO ‚â§ 8h]
        Admin[Admin Panel<br/>RTO: 8h]
        Logs[Logs Archive<br/>RTO: 24h]
    end
    
    style Criticidade_Critica fill:#ffcccc
    style Criticidade_Alta fill:#fff4cc
    style Criticidade_Media fill:#ccffcc
```

---

## üèóÔ∏è 3. Arquitetura de Recupera√ß√£o

### 3.1 Topologia Geral: Site Prim√°rio vs. Site de DR

```mermaid
graph TB
    subgraph Internet[üåê Internet]
        Users[üë• Usu√°rios Finais]
        Serasa[üè¢ Serasa Experian]
    end
    
    subgraph Route53[‚òÅÔ∏è AWS Route53 - DNS Global]
        DNS[DNS com Health Checks<br/>e Failover Autom√°tico]
    end
    
    subgraph Primary[üü¢ Site Prim√°rio - us-east-1]
        subgraph Primary_Network[VPC us-east-1]
            ALB1[ALB<br/>Multi-AZ]
            
            subgraph Primary_Compute[Compute Layer]
                EKS1[EKS Cluster<br/>3 AZs]
                ECS1[ECS Fargate<br/>Jobs]
            end
            
            subgraph Primary_Data[Data Layer]
                RDS1[(RDS PostgreSQL<br/>Multi-AZ<br/>Primary)]
                Redis1[ElastiCache<br/>Redis Cluster]
            end
            
            S31[S3 Buckets<br/>CRR Enabled]
        end
    end
    
    subgraph DR[üî¥ Site de DR - us-west-2]
        subgraph DR_Network[VPC us-west-2]
            ALB2[ALB<br/>Multi-AZ<br/>Standby]
            
            subgraph DR_Compute[Compute Layer]
                EKS2[EKS Cluster<br/>Minimal<br/>Auto-Scale]
                ECS2[ECS Fargate<br/>Standby]
            end
            
            subgraph DR_Data[Data Layer]
                RDS2[(RDS PostgreSQL<br/>Read Replica<br/>Promote-able)]
                Redis2[ElastiCache<br/>Redis Standby]
            end
            
            S32[S3 Buckets<br/>CRR Target]
        end
    end
    
    Users --> DNS
    Serasa --> DNS
    
    DNS -->|Normal| ALB1
    DNS -->|Failover| ALB2
    
    ALB1 --> EKS1
    ALB1 --> ECS1
    EKS1 --> RDS1
    EKS1 --> Redis1
    EKS1 --> S31
    
    ALB2 --> EKS2
    ALB2 --> ECS2
    EKS2 --> RDS2
    EKS2 --> Redis2
    EKS2 --> S32
    
    RDS1 -.Replica√ß√£o<br/>Ass√≠ncrona.-> RDS2
    Redis1 -.Backup<br/>Di√°rio.-> Redis2
    S31 -.CRR<br/>S√≠ncrono.-> S32
    
    style Primary fill:#d4edda
    style DR fill:#f8d7da
    style Route53 fill:#cce5ff
```

### 3.2 Estrat√©gias de Replica√ß√£o de Dados

#### 3.2.1 Banco de Dados (RDS PostgreSQL)

**Prim√°rio (us-east-1):**
- RDS Multi-AZ (failover autom√°tico entre AZs)
- Automated backups a cada 15 minutos
- Transaction logs (WAL) replicados para standby

**Secund√°rio (us-west-2):**
- Read Replica cross-region (replica√ß√£o ass√≠ncrona)
- Lag t√≠pico: < 5 segundos
- Pode ser promovida a master independente

**Processo de Failover:**
1. Multi-AZ failover autom√°tico (dentro de us-east-1) - RTO: 1-2 min
2. Se regi√£o inteira falhar ‚Üí promover Read Replica em us-west-2 - RTO: 30-60 min

#### 3.2.2 Object Storage (S3)

**Estrat√©gia:** Cross-Region Replication (CRR)

```
Bucket Primary (us-east-1)
    ‚îú‚îÄ‚îÄ /prod-data/
    ‚îÇ   ‚îî‚îÄ‚îÄ Replicado para: us-west-2 (‚â§ 15 min, 99.99% SLA)
    ‚îú‚îÄ‚îÄ /prod-uploads/
    ‚îÇ   ‚îî‚îÄ‚îÄ Replicado para: us-west-2 (‚â§ 15 min)
    ‚îî‚îÄ‚îÄ /prod-backups/
        ‚îî‚îÄ‚îÄ Replicado para: us-west-2 (‚â§ 1 hora)
```

**Versionamento:** Habilitado em ambas as regi√µes (RPO = 0)

#### 3.2.3 Cache (ElastiCache Redis)

**Estrat√©gia:** Backup di√°rio + Replica√ß√£o manual em caso de DR

**Prim√°rio:**
- Redis Cluster Mode Enabled (3 shards x 2 replicas)
- AOF (Append-Only File) habilitado
- Backup autom√°tico di√°rio (snapshot)

**Secund√°rio (Cold Standby):**
- Cluster provisionado mas com m√≠nimo de nodes
- Restaurado de snapshot em caso de failover
- RTO: 2 horas | RPO: 24 horas (√∫ltimo snapshot)

**Aceita√ß√£o de Perda:** Dados de cache/sess√£o podem ser reconstru√≠dos

---

## üîß 4. Procedimentos de Recupera√ß√£o

### 4.1 Procedimento Geral de DR

#### Fluxo de Decis√£o: Quando Ativar DR?

```mermaid
flowchart TD
    Start([üö® Incidente Detectado]) --> Assess{Avaliar<br/>Severidade}
    
    Assess -->|Degrada√ß√£o<br/>Parcial| Monitor[üìä Monitorar<br/>Sem DR]
    Assess -->|Indisponibilidade<br/>Completa| CheckTime{Tempo de<br/>Indisponibilidade}
    
    CheckTime -->|< 15 min| Wait[‚è≥ Aguardar<br/>Recupera√ß√£o<br/>Autom√°tica]
    CheckTime -->|> 15 min| CheckCause{Causa<br/>Identificada?}
    
    Wait --> Resolved{Resolvido?}
    Resolved -->|Sim| End([‚úÖ Fim])
    Resolved -->|N√£o - 15 min+| CheckCause
    
    CheckCause -->|AZ Failure<br/>us-east-1| MultiAZ[üîÑ Failover<br/>Multi-AZ<br/>Autom√°tico]
    CheckCause -->|Region Failure<br/>us-east-1| DR[üî¥ Ativar DR<br/>us-west-2]
    CheckCause -->|Desconhecida<br/>15+ min| Escalate{CTO<br/>Decide}
    
    MultiAZ --> Validate{Validar<br/>Servi√ßos}
    Validate -->|‚úÖ OK| Notify[üìß Notificar<br/>Stakeholders]
    Validate -->|‚ùå Falha| DR
    
    Escalate -->|Ativar DR| DR
    Escalate -->|Aguardar| Wait
    
    DR --> Execute[‚öôÔ∏è Executar<br/>Procedimentos<br/>de DR]
    Execute --> End
    Notify --> End
    
    Monitor --> End
    
    style Start fill:#ffcccc
    style DR fill:#ff6b6b
    style End fill:#51cf66
```

### 4.2 Passo a Passo T√©cnico: Failover para DR Site (us-west-2)

#### Fase 1: Prepara√ß√£o e Valida√ß√£o (0-15 minutos)

**Respons√°vel:** DevOps On-Call ‚Üí DevOps Lead ‚Üí CTO

**Checklist:**

- [ ] **[DevOps On-Call]** Confirmar indisponibilidade total de us-east-1
  ```bash
  # Validar status via AWS CLI
  aws ec2 describe-instance-status --region us-east-1 --query 'InstanceStatuses[*].[InstanceId,InstanceState.Name,InstanceStatus.Status]'
  
  # Validar via dashboard
  open https://console.aws.amazon.com/ec2/v2/home?region=us-east-1
  ```

- [ ] **[DevOps On-Call]** Verificar AWS Service Health Dashboard
  ```
  URL: https://health.aws.amazon.com/health/status
  Regi√£o: us-east-1
  ```

- [ ] **[DevOps On-Call]** Notificar CTO/CISO via CloudWatch Alarm + Slack + Celular
  ```
  Template: "CRITICAL: us-east-1 completamente down. 
  Ativa√ß√£o de DR requerida. Aguardando aprova√ß√£o."
  ```

- [ ] **[CTO]** Aprovar ativa√ß√£o de DR (verbal + Slack #incidents)
  ```
  Comando Slack: /incident declare "DR Activation - us-east-1 failure"
  ```

- [ ] **[DevOps Lead]** Convocar Equipe de DR (via Slack + Telefone)
  ```
  Pap√©is necess√°rios:
  - 2x DevOps Engineers
  - 1x DBA
  - 1x Network Engineer
  - 1x Security Engineer (se ataque cibern√©tico)
  ```

- [ ] **[DevOps Lead]** Abrir Google Meet War Room
  ```
  URL permanente: https://meet.google.com/[MEETING-CODE]
  ```

**Tempo Total Fase 1:** 10-15 minutos

---

#### Fase 2: Failover de Banco de Dados (15-45 minutos)

**Respons√°vel:** DBA Lead + DevOps Engineer

**Sub-etapa 2.1: Promover Read Replica a Master (15-30 min)**

- [ ] **[DBA]** Verificar lag de replica√ß√£o
  ```sql
  -- Executar em Read Replica (us-west-2)
  SELECT 
      pg_last_wal_receive_lsn(),
      pg_last_wal_replay_lsn(),
      EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) AS lag_seconds;
  ```
  **Aceit√°vel:** lag < 30 segundos

- [ ] **[DBA]** Promover Read Replica via AWS Console
  ```bash
  aws rds promote-read-replica \
      --db-instance-identifier prod-db-us-west-2-replica \
      --region us-west-2 \
      --backup-retention-period 7 \
      --preferred-backup-window "03:00-04:00" \
      --no-apply-immediately  # Executar imediatamente
  ```
  **Dura√ß√£o:** 5-10 minutos

- [ ] **[DBA]** Aguardar promo√ß√£o completar
  ```bash
  # Monitorar status
  aws rds describe-db-instances \
      --db-instance-identifier prod-db-us-west-2-replica \
      --region us-west-2 \
      --query 'DBInstances[0].DBInstanceStatus'
  
  # Status esperado: "available"
  ```

**Sub-etapa 2.2: Validar Integridade de Dados (5-10 min)**

- [ ] **[DBA]** Conectar ao novo master e validar
  ```sql
  -- Conectar: psql -h prod-db-us-west-2.xxxx.rds.amazonaws.com -U admin -d proddb
  
  -- Validar contagem de registros cr√≠ticos
  SELECT 'users' AS table_name, COUNT(*) FROM users
  UNION ALL
  SELECT 'transactions', COUNT(*) FROM transactions
  UNION ALL
  SELECT 'sessions', COUNT(*) FROM sessions;
  
  -- Verificar √∫ltima transa√ß√£o
  SELECT MAX(created_at) FROM transactions;
  ```
  **A√ß√£o:** Comparar com √∫ltimo snapshot conhecido

- [ ] **[DBA]** Habilitar backups autom√°ticos
  ```bash
  aws rds modify-db-instance \
      --db-instance-identifier prod-db-us-west-2-replica \
      --backup-retention-period 30 \
      --apply-immediately \
      --region us-west-2
  ```

- [ ] **[DBA]** Documentar RPO alcan√ßado
  ```
  RPO Contratual: 15 minutos
  RPO Alcan√ßado: [X] minutos (baseado em √∫ltima transa√ß√£o)
  Status: [CONFORME / N√ÉO CONFORME]
  ```

**Tempo Total Fase 2:** 25-40 minutos

---

#### Fase 3: Failover de Aplica√ß√µes (30-60 minutos)

**Respons√°vel:** DevOps Team

**Sub-etapa 3.1: Escalar EKS Cluster em us-west-2 (10-15 min)**

- [ ] **[DevOps]** Escalar node groups do EKS
  ```bash
  # Escalar de 2 nodes (standby) para 10 nodes (produ√ß√£o)
  aws eks update-nodegroup-config \
      --cluster-name prod-eks-us-west-2 \
      --nodegroup-name prod-ng-us-west-2 \
      --scaling-config minSize=10,maxSize=20,desiredSize=10 \
      --region us-west-2
  ```

- [ ] **[DevOps]** Aguardar nodes ficarem Ready
  ```bash
  kubectl get nodes --context=west-cluster -w
  
  # Aguardar at√© todos nodes mostrarem "Ready"
  ```

**Sub-etapa 3.2: Atualizar ConfigMaps com novo DB endpoint (5 min)**

- [ ] **[DevOps]** Atualizar ConfigMap com endpoint do novo master DB
  ```bash
  kubectl edit configmap app-config --context=west-cluster -n production
  
  # Alterar:
  # DB_HOST: prod-db-us-east-1.xxxx.rds.amazonaws.com
  # Para:
  # DB_HOST: prod-db-us-west-2.yyyy.rds.amazonaws.com
  ```

- [ ] **[DevOps]** Reiniciar deployments para pegar novo config
  ```bash
  kubectl rollout restart deployment/api-backend --context=west-cluster -n production
  kubectl rollout restart deployment/auth-service --context=west-cluster -n production
  kubectl rollout restart deployment/worker-jobs --context=west-cluster -n production
  ```

**Sub-etapa 3.3: Validar Health Checks (10-15 min)**

- [ ] **[DevOps]** Aguardar todos pods ficarem Running
  ```bash
  kubectl get pods --context=west-cluster -n production -w
  
  # Aguardar status: Running (X/X containers ready)
  ```

- [ ] **[DevOps]** Executar smoke tests
  ```bash
  # Health check geral
  curl -I https://api-west.[dominio].com/health
  # Esperado: HTTP/2 200
  
  # Smoke test autentica√ß√£o
  ./tests/smoke/auth_smoke_test.sh us-west-2
  
  # Smoke test APIs cr√≠ticas
  ./tests/smoke/api_smoke_test.sh us-west-2
  ```

- [ ] **[QA/DevOps]** Validar fluxo end-to-end
  ```
  Testar manualmente:
  1. Login de usu√°rio
  2. Consulta de dados (Serasa endpoint)
  3. Transa√ß√£o simples
  4. Upload de arquivo
  ```

**Tempo Total Fase 3:** 30-45 minutos

---

#### Fase 4: Failover de DNS (45-60 minutos)

**Respons√°vel:** DevOps Engineer + Network Engineer

- [ ] **[DevOps]** Atualizar Route53 para apontar para us-west-2
  ```bash
  # Op√ß√£o 1: Autom√°tico (Health Check falha)
  # Route53 detecta falha em us-east-1 e redireciona automaticamente
  # TTL: 60 segundos ‚Üí propaga√ß√£o em ~5 minutos
  
  # Op√ß√£o 2: Manual (se autom√°tico falhar)
  aws route53 change-resource-record-sets \
      --hosted-zone-id Z1234567ABCD \
      --change-batch file://dns-failover-west.json
  ```

**Arquivo:** `dns-failover-west.json`
```json
{
  "Changes": [{
    "Action": "UPSERT",
    "ResourceRecordSet": {
      "Name": "api.[dominio].com",
      "Type": "CNAME",
      "TTL": 60,
      "ResourceRecords": [{
        "Value": "prod-alb-us-west-2-xxxx.elb.amazonaws.com"
      }]
    }
  }]
}
```

- [ ] **[DevOps]** Verificar propaga√ß√£o de DNS
  ```bash
  # Verificar em m√∫ltiplos servidores DNS
  dig @8.8.8.8 api.[dominio].com
  dig @1.1.1.1 api.[dominio].com
  dig @resolver1.opendns.com api.[dominio].com
  
  # Todos devem apontar para ALB us-west-2
  ```

- [ ] **[DevOps]** Aguardar TTL expirar (60 segundos)
  ```bash
  # Testar de m√∫ltiplas localiza√ß√µes
  curl -I https://api.[dominio].com/health
  ```

**Tempo Total Fase 4:** 5-15 minutos (+ tempo de propaga√ß√£o DNS)

---

#### Fase 5: Valida√ß√£o Final e Monitoramento (60-120 minutos)

**Respons√°vel:** DevOps Lead + CTO

- [ ] **[DevOps]** Monitorar dashboards de produ√ß√£o
  ```
  M√©tricas cr√≠ticas:
  - Request Rate (deve retornar ao normal em 10-15 min)
  - Error Rate (deve estar < 1%)
  - Lat√™ncia P95 (deve estar < 500ms)
  - Database Connections (deve estabilizar)
  ```

- [ ] **[DevOps]** Validar tr√°fego de Serasa Experian especificamente
  ```bash
  # Filtrar logs de Serasa
  kubectl logs -f deployment/api-backend --context=west-cluster -n production | grep "serasa"
  
  # Verificar taxa de sucesso
  # Esperado: > 99% success rate
  ```

- [ ] **[Suporte]** Monitorar volume de tickets/chamados
  ```
  Zendesk Dashboard: Comparar com baseline normal
  Esperado: Pico nos primeiros 30 min, depois normalizar
  ```

- [ ] **[DevOps Lead]** Declarar RTO alcan√ßado
  ```
  Timestamp In√≠cio Incidente: [HH:MM]
  Timestamp Servi√ßos Restaurados: [HH:MM]
  RTO Alcan√ßado: [XX] minutos
  RTO Contratual: 120 minutos
  Status: [CONFORME / N√ÉO CONFORME]
  ```

- [ ] **[CTO]** Aprovar declara√ß√£o de "Servi√ßos Restaurados"
  ```
  Slack #incidents: "@here DR conclu√≠do. Servi√ßos operando em us-west-2."
  ```

**Tempo Total Fase 5:** Monitoramento cont√≠nuo (primeiras 24-48 horas cr√≠ticas)

---

### 4.3 Scripts de Automa√ß√£o

#### Script 1: `dr-failover-complete.sh`

```bash
#!/bin/bash
############################################################
# DR Failover Completo: us-east-1 ‚Üí us-west-2
# Autor: [NOME - DevOps Lead]
# √öltima Atualiza√ß√£o: [DATA]
# Uso: ./dr-failover-complete.sh [--auto-approve]
############################################################

set -euo pipefail

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Configura√ß√µes
AWS_REGION_DR="us-west-2"
EKS_CLUSTER_DR="prod-eks-us-west-2"
RDS_REPLICA_ID="prod-db-us-west-2-replica"
ROUTE53_HOSTED_ZONE="Z1234567ABCD"

echo -e "${RED}========================================${NC}"
echo -e "${RED}  ‚ö†Ô∏è  DR FAILOVER PARA US-WEST-2  ‚ö†Ô∏è${NC}"
echo -e "${RED}========================================${NC}"
echo ""

# Confirma√ß√£o (se n√£o --auto-approve)
if [[ "${1:-}" != "--auto-approve" ]]; then
    echo -e "${YELLOW}Esta opera√ß√£o ir√°:${NC}"
    echo "  1. Promover RDS Read Replica a Master"
    echo "  2. Escalar EKS cluster em us-west-2"
    echo "  3. Atualizar DNS para us-west-2"
    echo ""
    read -p "Voc√™ confirma a ativa√ß√£o do DR? (digite 'CONFIRMO'): " confirm
    
    if [[ "$confirm" != "CONFIRMO" ]]; then
        echo -e "${RED}‚ùå Opera√ß√£o cancelada.${NC}"
        exit 1
    fi
fi

echo ""
echo -e "${GREEN}‚úÖ Iniciando DR Failover...${NC}"
echo ""

# Etapa 1: Promover RDS Replica
echo -e "${YELLOW}[Etapa 1/5] Promovendo RDS Read Replica...${NC}"
aws rds promote-read-replica \
    --db-instance-identifier "$RDS_REPLICA_ID" \
    --region "$AWS_REGION_DR" \
    --backup-retention-period 7 \
    --no-apply-immediately

echo "  Aguardando promo√ß√£o completar (pode levar 5-10 min)..."
aws rds wait db-instance-available \
    --db-instance-identifier "$RDS_REPLICA_ID" \
    --region "$AWS_REGION_DR"

echo -e "${GREEN}  ‚úÖ RDS promovido com sucesso.${NC}"
echo ""

# Etapa 2: Escalar EKS
echo -e "${YELLOW}[Etapa 2/5] Escalando EKS Cluster...${NC}"
aws eks update-nodegroup-config \
    --cluster-name "$EKS_CLUSTER_DR" \
    --nodegroup-name "prod-ng-us-west-2" \
    --scaling-config minSize=10,maxSize=20,desiredSize=10 \
    --region "$AWS_REGION_DR"

echo "  Aguardando nodes ficarem Ready..."
sleep 60  # Aguardar provisionamento

kubectl get nodes --context=west-cluster
echo -e "${GREEN}  ‚úÖ EKS escalado com sucesso.${NC}"
echo ""

# Etapa 3: Atualizar ConfigMaps
echo -e "${YELLOW}[Etapa 3/5] Atualizando ConfigMaps...${NC}"

NEW_DB_HOST=$(aws rds describe-db-instances \
    --db-instance-identifier "$RDS_REPLICA_ID" \
    --region "$AWS_REGION_DR" \
    --query 'DBInstances[0].Endpoint.Address' \
    --output text)

kubectl patch configmap app-config \
    --context=west-cluster \
    -n production \
    -p "{\"data\":{\"DB_HOST\":\"$NEW_DB_HOST\"}}"

echo -e "${GREEN}  ‚úÖ ConfigMaps atualizados.${NC}"
echo ""

# Etapa 4: Reiniciar Deployments
echo -e "${YELLOW}[Etapa 4/5] Reiniciando Deployments...${NC}"
kubectl rollout restart deployment/api-backend --context=west-cluster -n production
kubectl rollout restart deployment/auth-service --context=west-cluster -n production
kubectl rollout restart deployment/worker-jobs --context=west-cluster -n production

echo "  Aguardando rollout completar..."
kubectl rollout status deployment/api-backend --context=west-cluster -n production --timeout=5m
kubectl rollout status deployment/auth-service --context=west-cluster -n production --timeout=5m

echo -e "${GREEN}  ‚úÖ Deployments reiniciados.${NC}"
echo ""

# Etapa 5: Atualizar DNS
echo -e "${YELLOW}[Etapa 5/5] Atualizando DNS (Route53)...${NC}"

ALB_DR=$(kubectl get svc api-backend --context=west-cluster -n production -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

cat > /tmp/dns-change.json <<EOF
{
  "Changes": [{
    "Action": "UPSERT",
    "ResourceRecordSet": {
      "Name": "api.[dominio].com",
      "Type": "CNAME",
      "TTL": 60,
      "ResourceRecords": [{"Value": "$ALB_DR"}]
    }
  }]
}
EOF

aws route53 change-resource-record-sets \
    --hosted-zone-id "$ROUTE53_HOSTED_ZONE" \
    --change-batch file:///tmp/dns-change.json

echo -e "${GREEN}  ‚úÖ DNS atualizado (propaga√ß√£o em ~5 min).${NC}"
echo ""

# Resumo
echo -e "${GREEN}========================================${NC}"
echo -e "${GREEN}  ‚úÖ DR FAILOVER CONCLU√çDO COM SUCESSO${NC}"
echo -e "${GREEN}========================================${NC}"
echo ""
echo "Pr√≥ximos passos:"
echo "  1. Validar smoke tests: ./tests/smoke/run_all.sh us-west-2"
echo "  2. Monitorar dashboards: CloudWatch Console"
echo "  3. Notificar Serasa Experian: Ver template em se√ß√£o 7.1 do BCP"
echo ""
echo -e "${YELLOW}‚ö†Ô∏è  Lembre-se: Este √© o site de DR. Planejar failback ap√≥s us-east-1 normalizar.${NC}"
```

**Localiza√ß√£o:** `/opt/scripts/dr-failover-complete.sh`  
**Permiss√µes:** `chmod +x` (apenas DevOps team)

---

## üë• 5. Equipe T√©cnica e Responsabilidades

### 5.1 Organograma de Resposta a Desastres

```mermaid
graph TD
    A[DR Commander<br/>CTO] --> B[Technical Lead<br/>DevOps Lead]
    A --> C[Database Lead<br/>DBA Senior]
    A --> D[Communications<br/>CISO/PR]
    
    B --> E1[DevOps Engineer 1<br/>AWS Infrastructure]
    B --> E2[DevOps Engineer 2<br/>Kubernetes/EKS]
    B --> E3[Network Engineer<br/>DNS/Route53/VPN]
    
    C --> F1[DBA 1<br/>RDS/PostgreSQL]
    C --> F2[DBA 2<br/>Backup/Restore]
    
    D --> G1[Internal Comms<br/>Slack/Email]
    D --> G2[External Comms<br/>Serasa/Clientes]
    
    style A fill:#ff6b6b
    style B fill:#4ecdc4
    style C fill:#45b7d1
    style D fill:#96ceb4
```

### 5.2 Matriz de Escala√ß√£o 24/7

| N√≠vel | Papel | Nome | Contato Prim√°rio | Contato Backup | Hor√°rio |
|-------|-------|------|------------------|----------------|---------|
| **L1** | DevOps On-Call | [NOME 1] | [CELULAR 1] | [CELULAR 2] | 24/7 (rotativo semanal) |
| **L1** | DevOps On-Call | [NOME 2] | [CELULAR 2] | [CELULAR 1] | 24/7 (rotativo semanal) |
| **L2** | DevOps Lead | [NOME] | [CELULAR] | [EMAIL] | 24/7 (permanente) |
| **L2** | DBA Senior | [NOME] | [CELULAR] | [EMAIL] | 24/7 (permanente) |
| **L3** | CTO | [NOME] | [CELULAR] | [EMAIL] | 24/7 (emerg√™ncias) |
| **L3** | CISO | [NOME] | [CELULAR] | [EMAIL] | 24/7 (emerg√™ncias) |

**Pol√≠tica de Escala√ß√£o:**
- **L1 ‚Üí L2:** Ap√≥s 15 minutos sem resolu√ß√£o
- **L2 ‚Üí L3:** Ap√≥s 30 minutos ou se decis√£o executiva necess√°ria
- **L3 ativa DR:** CTO tem autoridade final para ativar failover

**Ferramenta de On-Call:** CloudWatch Alarms + Slack (escala√ß√£o via telefone)

---

## üß™ 6. Testes de Recupera√ß√£o

### 6.1 Metodologia de Testes

#### 6.1.1 Teste Tabletop (Trimestral)

**Objetivo:** Validar conhecimento da equipe sobre procedimentos de DR

**Dura√ß√£o:** 2-3 horas

**Metodologia:**
1. Apresentar cen√°rio: "us-east-1 completamente indispon√≠vel"
2. Equipe discute procedimentos sem executar
3. Identificar gaps de documenta√ß√£o ou conhecimento

**Pr√≥ximo Teste:** [DATA]

**Crit√©rios de Sucesso:**
- [ ] 100% da equipe de DR participou
- [ ] Todos os passos cr√≠ticos foram mencionados
- [ ] Tempo estimado < RTO contratual (2 horas)

#### 6.1.2 Teste de DR Simulado (Semestral)

**Objetivo:** Executar failover t√©cnico em ambiente de staging

**Dura√ß√£o:** 4-6 horas

**Metodologia:**
1. Executar failover completo em staging
2. Validar funcionamento de todos os servi√ßos
3. Medir RTO e RPO alcan√ßados
4. Executar failback

**Pr√≥ximo Teste:** [DATA]

**Crit√©rios de Sucesso:**
- [ ] Failover conclu√≠do em < 2 horas
- [ ] RPO < 15 minutos
- [ ] 100% dos smoke tests passaram
- [ ] Failback executado com sucesso

#### 6.1.3 Teste de DR Completo (Anual)

**Objetivo:** Failover REAL em ambiente de produ√ß√£o

**Dura√ß√£o:** 4-8 horas (inclui failback)

**Metodologia:**
1. Comunicar clientes com 1 semana de anteced√™ncia
2. Janela de manuten√ß√£o (madrugada de s√°bado/domingo)
3. Executar failover us-east-1 ‚Üí us-west-2
4. Operar em us-west-2 por 24-48 horas
5. Executar failback para us-east-1

**Pr√≥ximo Teste:** [DATA]

**Crit√©rios de Sucesso:**
- [ ] RTO contratual cumprido (< 2 horas)
- [ ] RPO contratual cumprido (< 15 minutos)
- [ ] SLA de disponibilidade mantido (99.9%)
- [ ] Zero incidentes cr√≠ticos durante teste
- [ ] Serasa Experian validou funcionalidade

### 6.2 Cronograma Anual de Testes

| M√™s | Tipo de Teste | Status | Data Planejada | Data Executada | Resultado |
|-----|---------------|--------|----------------|----------------|-----------|
| Jan | Tabletop | ‚úÖ Completo | 15/01/[ANO] | 15/01/[ANO] | ‚úÖ Aprovado |
| Abr | Tabletop | ‚è∏Ô∏è Planejado | 15/04/[ANO] | - | - |
| Jun | **DR Simulado (Staging)** | ‚è∏Ô∏è Planejado | 30/06/[ANO] | - | - |
| Jul | Tabletop | ‚è∏Ô∏è Planejado | 15/07/[ANO] | - | - |
| Out | Tabletop | ‚è∏Ô∏è Planejado | 15/10/[ANO] | - | - |
| Dez | **DR Completo (Produ√ß√£o)** | ‚è∏Ô∏è Planejado | 07/12/[ANO] | - | - |

### 6.3 M√©tricas de Sucesso dos Testes

| M√©trica | Target | √öltimo Teste | Status |
|---------|--------|--------------|--------|
| **RTO Alcan√ßado** | ‚â§ 2 horas | [X.X] horas | ‚úÖ / ‚ùå |
| **RPO Alcan√ßado** | ‚â§ 15 minutos | [X] minutos | ‚úÖ / ‚ùå |
| **Taxa de Sucesso (Smoke Tests)** | 100% | [XX]% | ‚úÖ / ‚ùå |
| **Downtime Total** | ‚â§ 2 horas | [X.X] horas | ‚úÖ / ‚ùå |
| **Participa√ß√£o da Equipe** | 100% | [XX]% | ‚úÖ / ‚ùå |

---

## 7. Integra√ß√£o com Backup e Restore

**Refer√™ncia Completa:** Ver **[06-politica-backup-restauracao.md](06-politica-backup-restauracao.md)**

### 7.1 Resumo de Pol√≠ticas de Backup

| Tipo de Backup | Frequ√™ncia | Reten√ß√£o | Localiza√ß√£o | RPO |
|----------------|-----------|----------|-------------|-----|
| **RDS Automated Backup** | A cada 15 min | 30 dias | us-east-1 + us-west-2 | 15 min |
| **RDS Manual Snapshot** | Semanal (domingos) | 90 dias | us-east-1 + us-west-2 | 7 dias |
| **S3 Versioning** | Cont√≠nuo | 365 dias | us-east-1 + us-west-2 | 0 (zero) |
| **Redis AOF** | Cont√≠nuo | 7 dias | us-east-1 | 30 min |
| **Redis Snapshot** | Di√°rio | 30 dias | us-east-1 + us-west-2 | 24 horas |

### 7.2 Pontos de Verifica√ß√£o de Integridade

**Antes de Failover:**
- [ ] √öltimo backup RDS foi executado com sucesso? (Verificar CloudWatch)
- [ ] Lag de replica√ß√£o < 30 segundos? (Verificar m√©tricas RDS)
- [ ] S3 CRR est√° atualizado? (Verificar m√©tricas S3)

**Durante Failover:**
- [ ] Read Replica promovida sem erros?
- [ ] Integridade de dados validada? (contagem de registros)

**P√≥s-Failover:**
- [ ] Backups autom√°ticos habilitados no novo master?
- [ ] Replica√ß√£o para nova read replica configurada?

---

## ‚úÖ Checklist de Valida√ß√£o do PRD

- [ ] Todas as se√ß√µes obrigat√≥rias est√£o preenchidas
- [ ] Placeholders substitu√≠dos por informa√ß√µes reais
- [ ] RTOs e RPOs testados e documentados
- [ ] Scripts de automa√ß√£o validados em staging
- [ ] Matriz de escala√ß√£o 24/7 atualizada
- [ ] Diagramas Mermaid renderizando corretamente
- [ ] Procedimentos de failover testados (no m√≠nimo tabletop)
- [ ] Integra√ß√£o com BCP validada (refer√™ncias cruzadas corretas)
- [ ] Serasa Experian foi informada sobre este PRD
- [ ] Cronograma de testes anuais aprovado
- [ ] Documento aprovado pelo CTO (ver se√ß√£o abaixo)

---

## ‚úçÔ∏è Aprova√ß√£o

| Papel | Nome | Assinatura | Data |
|-------|------|------------|------|
| **Elaborado por** | [NOME - DevOps Lead] | __________ | [DATA] |
| **Revisado por** | [NOME - CISO] | __________ | [DATA] |
| **Aprovado por** | [NOME - CTO] | __________ | [DATA] |

---

## üìö Refer√™ncias Cruzadas

- **[01-plano-continuidade-negocios.md](01-plano-continuidade-negocios.md)** - BCP (estrat√©gias de continuidade)
- **[06-politica-backup-restauracao.md](06-politica-backup-restauracao.md)** - Pol√≠ticas de backup detalhadas
- **[05-relatorio-testes-anuais.md](05-relatorio-testes-anuais.md)** - Template de relat√≥rio de testes

---

## üìñ Gloss√°rio

| Termo | Defini√ß√£o |
|-------|-----------|
| **DR (Disaster Recovery)** | Recupera√ß√£o de Desastres |
| **RTO** | Recovery Time Objective (Tempo Objetivo de Recupera√ß√£o) |
| **RPO** | Recovery Point Objective (Ponto Objetivo de Recupera√ß√£o) |
| **Failover** | Transfer√™ncia de servi√ßos para site secund√°rio |
| **Failback** | Retorno de servi√ßos para site prim√°rio |
| **Multi-AZ** | M√∫ltiplas Zonas de Disponibilidade (AWS) |
| **CRR** | Cross-Region Replication (Replica√ß√£o entre Regi√µes) |
| **Read Replica** | R√©plica de leitura de banco de dados |
| **WAL** | Write-Ahead Log (PostgreSQL) |
| **AOF** | Append-Only File (Redis) |
| **Health Check** | Verifica√ß√£o de sa√∫de de servi√ßos |

---

**üîí Classifica√ß√£o:** CONFIDENCIAL - USO INTERNO  
**üìÅ Categoria:** Compliance - ISO 22301, ISO 27001  
**üìÖ Validade:** [DATA] at√© [DATA + 6 MESES]  
**üîÑ Pr√≥xima Revis√£o:** [DATA + 6 MESES]  
**üë§ Respons√°vel:** [NOME - CTO/DevOps Lead]

---

**Vers√£o do Template:** 1.0 - Gen√©rico  
**Data de Cria√ß√£o:** 09/10/2025  
**Conformidade:** ISO 22301:2019, ISO 27001:2022, SOC 2 (Availability)  
**Para uso com:** Serasa Experian e demais clientes enterprise

